{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Oil Close</th>\n",
       "      <th>Enb Close</th>\n",
       "      <th>Target Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>14.707242</td>\n",
       "      <td>81.769997</td>\n",
       "      <td>14.897686</td>\n",
       "      <td>14.559792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>14.467640</td>\n",
       "      <td>83.180000</td>\n",
       "      <td>14.559792</td>\n",
       "      <td>14.513723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>14.295634</td>\n",
       "      <td>82.660004</td>\n",
       "      <td>14.513723</td>\n",
       "      <td>14.538293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>14.464572</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>14.538293</td>\n",
       "      <td>14.436925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>14.375491</td>\n",
       "      <td>82.519997</td>\n",
       "      <td>14.436925</td>\n",
       "      <td>14.427713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>47.740002</td>\n",
       "      <td>41.549999</td>\n",
       "      <td>41.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.119999</td>\n",
       "      <td>47.020000</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.189999</td>\n",
       "      <td>48.119999</td>\n",
       "      <td>41.279999</td>\n",
       "      <td>41.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.790001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>40.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>48.400002</td>\n",
       "      <td>40.820000</td>\n",
       "      <td>40.709999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2689 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Low  Oil Close  Enb Close  Target Close\n",
       "Date                                                     \n",
       "2010-01-05  14.707242  81.769997  14.897686     14.559792\n",
       "2010-01-06  14.467640  83.180000  14.559792     14.513723\n",
       "2010-01-07  14.295634  82.660004  14.513723     14.538293\n",
       "2010-01-08  14.464572  82.750000  14.538293     14.436925\n",
       "2010-01-11  14.375491  82.519997  14.436925     14.427713\n",
       "...               ...        ...        ...           ...\n",
       "2020-12-21  40.639999  47.740002  41.549999     41.230000\n",
       "2020-12-22  41.119999  47.020000  41.230000     41.279999\n",
       "2020-12-23  41.189999  48.119999  41.279999     41.250000\n",
       "2020-12-29  40.790001  48.000000  40.799999     40.820000\n",
       "2020-12-30  40.639999  48.400002  40.820000     40.709999\n",
       "\n",
       "[2689 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('eng_2020.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=[\"SU Close\", \"Volume\", \"Open\", \"Gas Close\", \"TSX Close\", \"High\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df.iloc[:, :-1]\n",
    "df_output = df[[\"Enb Close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_input, df_output, test_size=0.3, random_state=42, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1882, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Oil Close</th>\n",
       "      <th>Enb Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-11</th>\n",
       "      <td>40.012272</td>\n",
       "      <td>48.070000</td>\n",
       "      <td>40.280537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-12</th>\n",
       "      <td>40.044792</td>\n",
       "      <td>48.230000</td>\n",
       "      <td>40.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>40.532544</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>40.540672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>40.500030</td>\n",
       "      <td>49.889999</td>\n",
       "      <td>40.719521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>40.475641</td>\n",
       "      <td>49.889999</td>\n",
       "      <td>40.768295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>47.740002</td>\n",
       "      <td>41.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.119999</td>\n",
       "      <td>47.020000</td>\n",
       "      <td>41.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.189999</td>\n",
       "      <td>48.119999</td>\n",
       "      <td>41.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.790001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>40.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>48.400002</td>\n",
       "      <td>40.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Low  Oil Close  Enb Close\n",
       "Date                                       \n",
       "2017-09-11  40.012272  48.070000  40.280537\n",
       "2017-09-12  40.044792  48.230000  40.573196\n",
       "2017-09-13  40.532544  49.299999  40.540672\n",
       "2017-09-14  40.500030  49.889999  40.719521\n",
       "2017-09-15  40.475641  49.889999  40.768295\n",
       "...               ...        ...        ...\n",
       "2020-12-21  40.639999  47.740002  41.549999\n",
       "2020-12-22  41.119999  47.020000  41.230000\n",
       "2020-12-23  41.189999  48.119999  41.279999\n",
       "2020-12-29  40.790001  48.000000  40.799999\n",
       "2020-12-30  40.639999  48.400002  40.820000\n",
       "\n",
       "[807 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaler = MinMaxScaler()\n",
    "x_test_scaler = MinMaxScaler()\n",
    "\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaler.fit(x_train)\n",
    "x_test_scaler.fit(x_test)\n",
    "\n",
    "y_train_scaler.fit(y_train)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "x_train = x_train_scaler.transform(x_train)\n",
    "x_test = x_test_scaler.transform(x_test)\n",
    "\n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "y_test = y_test_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1\n",
    "batch = 44\n",
    "features = 3\n",
    "\n",
    "train_generator = TimeseriesGenerator(x_train, y_train, length=length, sampling_rate=1, batch_size=batch)\n",
    "test_generator = TimeseriesGenerator(x_test, y_test, length=length, sampling_rate=1, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "units = 64\n",
    "drop = 0.2\n",
    "\n",
    "#1st layer\n",
    "model.add(LSTM(units=units, return_sequences=True, input_shape=(length, features)))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "#2nd layer\n",
    "model.add(LSTM(units=units, return_sequences=True))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "#3rd layer\n",
    "model.add(LSTM(units=units))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 64)             17408     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 83,521\n",
      "Trainable params: 83,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_loss = logs[\"val_loss\"]\n",
    "        if val_loss < self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.1075 - val_loss: 0.1985\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 0.1215 - val_loss: 0.0500\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 0.0534 - val_loss: 0.0444\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0311 - val_loss: 0.0126\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 2s 51ms/step - loss: 0.0132 - val_loss: 0.0031\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0093 - val_loss: 0.0028\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.0088 - val_loss: 0.0032\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 2s 50ms/step - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 0.0079 - val_loss: 0.0029\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 2s 51ms/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0066 - val_loss: 0.0047\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 2s 54ms/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0045 - val_loss: 0.0080\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 3s 58ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 2s 57ms/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0037 - val_loss: 0.0065\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 2s 56ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0028 - val_loss: 0.0052\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0026 - val_loss: 0.0055\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.0026 - val_loss: 0.0052\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 2s 55ms/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0025 - val_loss: 0.0064\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 115/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 150/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 151/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 152/1000\n",
      "43/43 [==============================] - 9s 205ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 153/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 154/1000\n",
      "43/43 [==============================] - 7s 152ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 155/1000\n",
      "43/43 [==============================] - 6s 138ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 156/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 157/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 158/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 159/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 160/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 161/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 162/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 163/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 164/1000\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 165/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 166/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 167/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 168/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 169/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 170/1000\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 171/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 172/1000\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 173/1000\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 174/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 175/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 176/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 177/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 178/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 179/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 180/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 181/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 182/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 183/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 184/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 185/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 186/1000\n",
      "43/43 [==============================] - 3s 60ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 187/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 188/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 189/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 190/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 191/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 192/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0019 - val_loss: 0.0036\n",
      "Epoch 193/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 194/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 195/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 196/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 197/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 198/1000\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 199/1000\n",
      "43/43 [==============================] - 4s 81ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 200/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 201/1000\n",
      "43/43 [==============================] - 3s 59ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 202/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 203/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 204/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 205/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 206/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 207/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 208/1000\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 209/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 210/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 211/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 212/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 213/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 214/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 215/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 216/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 217/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 218/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 219/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 220/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 221/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 222/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 223/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 224/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 225/1000\n",
      "43/43 [==============================] - 3s 61ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 226/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 227/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 228/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 229/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 230/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 231/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 232/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 233/1000\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 234/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 235/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 236/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 237/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 238/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 239/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 240/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 241/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 242/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 243/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 244/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 245/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 246/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 247/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 248/1000\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 249/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 250/1000\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 251/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 252/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 253/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 254/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 255/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0017 - val_loss: 0.0045\n",
      "Epoch 256/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 257/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 258/1000\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 259/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 260/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 261/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0016 - val_loss: 0.0037\n",
      "Epoch 262/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 263/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0017 - val_loss: 0.0051\n",
      "Epoch 264/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 265/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 266/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 267/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 268/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 269/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 270/1000\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 271/1000\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 272/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 273/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 274/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 275/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 276/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 277/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 278/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 279/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0017 - val_loss: 0.0046\n",
      "Epoch 280/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 281/1000\n",
      "43/43 [==============================] - 4s 88ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 282/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 283/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 284/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 285/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 286/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 287/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 288/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 289/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 290/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 291/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 292/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 293/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 294/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 295/1000\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 296/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 297/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 298/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 299/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 300/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 301/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 302/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 303/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 304/1000\n",
      "43/43 [==============================] - 3s 74ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 305/1000\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.0016 - val_loss: 0.0058\n",
      "Epoch 306/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 307/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 308/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 309/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 310/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 311/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0031 - val_loss: 0.0081\n",
      "Epoch 312/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 313/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 314/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 315/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 316/1000\n",
      "43/43 [==============================] - 3s 76ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 317/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 318/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 319/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 320/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 321/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 322/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 323/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0014 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, mode='min')\n",
    "\n",
    "earlystop = ThresholdCallback(threshold=0.0013)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "fit = model.fit_generator(train_generator, epochs = 1000, validation_data=test_generator,\n",
    "                         shuffle=False, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012974461585001432"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = y_test_scaler.inverse_transform(predictions)\n",
    "real_prices = y_test_scaler.inverse_transform(y_test[1:].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-12</th>\n",
       "      <td>40.573196</td>\n",
       "      <td>40.244278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>40.540672</td>\n",
       "      <td>40.417439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>40.719521</td>\n",
       "      <td>40.625744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>40.768295</td>\n",
       "      <td>40.708626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>40.922752</td>\n",
       "      <td>40.723938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>41.549999</td>\n",
       "      <td>41.972683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.229221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.279999</td>\n",
       "      <td>41.277164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.799999</td>\n",
       "      <td>41.338428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.820000</td>\n",
       "      <td>40.885952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Real  Predicted\n",
       "Date                            \n",
       "2017-09-12  40.573196  40.244278\n",
       "2017-09-13  40.540672  40.417439\n",
       "2017-09-14  40.719521  40.625744\n",
       "2017-09-15  40.768295  40.708626\n",
       "2017-09-18  40.922752  40.723938\n",
       "...               ...        ...\n",
       "2020-12-21  41.549999  41.972683\n",
       "2020-12-22  41.230000  41.229221\n",
       "2020-12-23  41.279999  41.277164\n",
       "2020-12-29  40.799999  41.338428\n",
       "2020-12-30  40.820000  40.885952\n",
       "\n",
       "[806 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEUCAYAAAAlXv26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABicUlEQVR4nO2dd3wcxfXAv++qumRZ7nK3Me42tunFNJteQyghwaEFCAkJCSW/kARIgRAIhBYgQIDQAoQSCL0YY0wzYFyxjRvuRbK6dLq7nd8fs9fkUznpdHeS5vv5yN6dmd03O7v3dvbNmzeilMJgMBgM3RdHuitgMBgMhs7FKHqDwWDo5hhFbzAYDN0co+gNBoOhm2MUvcFgMHRzjKI3GAyGbk6PV/QiMldELkyg/BARqRERZzP514vI48mrYeYhIutF5Kh01yNZiMgwEVEi4rL3XxOR81IgN2nPioh8T0TeTMa5DN2PbqHobcVTbyvg0N/dnSFLKfWtUipPKRXsjPO3hogMFxFLRO5N4JiEXmbtRUR+JSLz4qSXiEijiEzowLnniEjQvrdVIrJIRE7oWI3jo5Q6Vin1aBvq1GkvPBGZad/nGhGpFpGVIvLD5sorpZ5QSs3qjLo0U7/19j0taZK+yH5pDrP3S0XkPyKyS0QqRWSJiMyx80Iv2Jomf2e2sQ5eEXnYfh62iciVrZQ/R0Q2iEitiLwoIsVtPZeIPGDfAytU/6i880Tkc/vYTSJyS6jTEFXmLBFZYcteIyKHROV9186rFpHlInJKW64/EbqForc50VbAob/Lky2g6c1LEz8AdgNniYg33ZVpwr+AA0VkeJP0s4AlSqmlHTz/R0qpPKAIeAh4JvrHGiJD7lMy2GJfbwFwDfAPERnXtFAar3cdcHZUPSYC2U3K/AvYCAwFeqOf3+1NyhQ1+e3+u43yrwdG2+c+HLhaRI6JV1BExgP3A98H+gF1QHRnqbVzfQVcBnwR5/Q5wM+AEmA/4Ejgl1Gyjwb+DPwQyAcOBdbaeYOAx4Er0ff5KuBJEenblgZoM0qpLv8HrAeOaiZvDjAfuBWtINcBx0blzwVuAj4FKoGXgGI7bxiggAuAb4F5UWkuu8xw4H2gGngLuBt4POr8PwA2AGXAb6Lrin7RXgussfOfCclu4VrXAJeifyzfaZJ3MrAIqLLLHQP8EQgCDUCNXb+Ya4hqhwvt7ZHAu3addgFPoH+MbWnvN4HfNkn7FPipvT3Kbq9K+9z/buM9ngPMj9rPta9hOvpH+hz6B1MFXAgUol8GW4HNwB8Ap32s034edqF/cD9uck/DbWHvXwSssO/xcmAftAKzgHq7Xa+2y+4PLAAq0MphZtR5WnxWmlzvTGBTk7SdwHfstvgQuB0ot6+tafuMt2WU28/K/7X2zAFZdhuW2fX/DOjXwm/uOuCzqLRbgV/bbTnMTqsBpjRzjmE0eQ4T/N1vBmZF7f8eeLqZsn8CnozaHwk0AvmJnAutS+a0Uq8rgZej9hcAFzRTdj9gR5z7fEB72qTZOiXzZOn6o3VF77d/rE60ktwCiJ0/177JE9DK4z+hH1/Ug/iYnZfd9OEEPgL+CnjRb+rqqOPH2Q/6wYDH/iH4iSj6nwEfA6X28fcDT7VwnYcAPqAXcBfw36i8fdHK82j0j3kQsHfUNUYrrj1+YMQq+lH2ebxAH/QL7o42tvf3gNVR+2PsH1Qfe/8ptDJwoBXLwW28x3OwFRngAq6w27oQrej9wCn2ebOBF+32zAX6ol82P7KPvwT4GhgMFAPv0YyiB86wn48ZgNhtMzReO9htXgYcZ9fjaHs/dO3NPitxrncmtqK3z3WqfY1j7LYIAD+x2yK7Sfvko19wv7DbOB/Yr7VnDvgR8DK6h+oEpgEFLf3mgJXAWLt8qOcerejfRr+UzgKGNDnHMFpQ9MA5wOJm8nrZx/aLSvsO+ssxXvmXgGuapNXY19jmc9E2Rf8icLO97UQ//9cC3wCb0C/47Kj894GT7O1T7DK5SdWRyTxZuv7sh64G3QsJ/V1k580Bvokqm2Pf1P72/tzQTbH3x9k3xhn1II6I93ACQ9A/uNyo/CeJKPrfEqW4bdmNRBT9CuDIqPwB6B9zcw/+g8CL9vYBdtm+9v79wO3NHDeXBBR9nONPAb5s0t7NKfocdK/6QHv/j8BLUfmPAQ8ApQne4zl2W1ege+IfR7Xj9cC8qLL90C/E7Ki0s4H37O13gUui8mbRvKJ/A7iihecuWtFfA/yrSZk3gPNae1binHsm+ouhAt0rXwScFdUW38Zpn/lR1/plM+dt9pkDzkf3Pie18Td3FLpXfxP66/Et+zzRir4XcDOwDP1luQiY0eQ5rGjyN7YN8gfbx2ZFpR0NrG+m/DvR99xO22y3c5vPRSuKHm2e2QSU2PsD7XMvtNu6BP3i+2PUMReg9VcAbVI6PpHfRlv+upON/hSlVFHU3z+i8raFNpRSdfZmXlT+xqjtDYAbfUPi5UczENitlKptcnx0fvhYW3ZZVP5Q4AURqRCRCvSPMIhWVDGISDa6d/mEfa6P0Oakc+wig9Gf4x1GRPqKyNMisllEqtCf8yWtHWfXqw54FviBiAi6hx89sHk1umf8qYgsE5HzE6jax/a9LVFK7a+UejsqL/oeDUXfw61RbXs/umcPTe4LsfesKYm061DgjJBMW+7B6B94a89KPLbY11uslJqilHo6Kq+5Z7K1Orf0zP0L/WJ6WkS22IOK7lbq+C/0MzgH/RKPQSm1Wyl1rVJqvC1jEfCi/WyEKGny213RikzQihG0XZuo7eoWyhc0SQuVT/RccbEHUW9Gm4Z32cn19v93KaW22ul/RX/1YQ/m34J+4XiAw4AHRWRKIrJbozsp+o4wOGp7CLqHsysqTTVz3Fagl4jkNjk+Or80tGMr695R+RvRD0X0Q56llNocR9ap6IfvXtsrYBvaVPCDqHONbKaeTesfUjY5UWn9o7Zvso+ZpJQqAM5FK+e28ijwXXSvKB94JVwRpbYppS5SSg1EmwruFZFRCZy7OaKvcSO6Rx+tQApsZQP6vjS9582RSLtuRPfoo+9nrlLqZlp/VhKluWcyVI/m6tzsM6eU8iulblBKjQMOBE4g8nzFr4RSG9DjXscBz7dSdhfafDkQbTJrN0qp3eg2nRyVPBn95RCPZdFlRWQE2nS1qh3n2gN74PYfaKeQJU3quYnm79cU9NfoQqWUpZT6DPgE/bWUNIyi15wrIuNEJAe4EXhOtcF90n7IFwI3iIhHRA4GTowq8hxwoogcKCIe4AZiFeZ9wB9FZCiAiPQRkZObEXce8DAwEf1wTAEOAqbY3g4PAT8UkSNFxCEig0Rkb/vY7cCIqHrvRH+2nisiTrtXHa0Y8rFNYbZXwFWttUUTPkB/gj+AHtBqDGWIyBkiEnr57Ub/AJLqqqqU2ooeFL5NRArs9hgpIofZRZ4Bfmq7/vVC20+b40HglyIyTTSjQveLJu2K/vI5UURm2+2aJdpNsrQNz0oyeQXoLyI/s90G80VkPzuv2WdORA4XkYmi54hUoTs8bbk3FwBHNPlawT7nn0Vkgoi4RCQfPUb2jVKqbI+zJM5jwHUi0st+1i8CHmmm7BPoe3OI/bK9EXheKRXqtbd4LvueZaF/v2773jrsvCPs85+ulPo0jux/Aj+xv5R7ocdJQp2fz4BDQj14EZmKHotbnHBrtESybUHp+EPbC0PeD6G/F1QT22VUeQWMsrfnEvG6qUIPRoXsa8PY05Ydk4b+oX9gy4zndTMHbWIJed1sBg6x8xzoEfqV6M/ENcCf4lzfILT9bmKcvFeBW+3tU9EPSDV64Ge2nX4AsAqtWO+0045F98QqgNvQA0Ihu/R44HP7mhahB/U2NWnvuDb6qDLX2+20X5P0W+w2qLGv9+KovGXA95o53x73sYmsx5ukFQJ/R/emKoEvidi4XWiPlTK7DVrzurnEvkc1wFJgqp1+sn1vK4Bf2mn72W1Zjvae+B/2IGRrz0qT+s+kiddNS23RNA3tXPCOfc+3Ade29syhbfsr0V9824E7aX68KO4zwJ42+ruA1fY170QruLFNfks1Tf6utPO/Byxr4Rnzojs/VXZ9r2ySX4P9W7P3z7HvVy1R3nVtPNdcu67RfzPtvPfQv8/oa3gt6lg32pWzwr4XdxI7HnA5+vdajfYC+0Uy9aNSKux5YkgBIpKHvtmjlVLr0lwdg8HQQzCmm05GRE4UkRz7c/FWYAm6N2QwGAwpwSj6zudktN/+FvTMu7OU+YwyGAwpxJhuDAaDoZtjevQGg8HQzcm44E8lJSVq2LBh6a6GwWAwdCk+//zzXUqpPvHyMk7RDxs2jIULF6a7GgaDwdClEJFmZ1ob043BYDB0c4yiNxgMhm6OUfQGg8HQzck4G73BYOie+P1+Nm3aRENDQ7qr0qXJysqitLQUt7u1wKIRjKI3GAwpYdOmTeTn5zNs2DBioxQb2opSirKyMjZt2sTw4U1X7GweY7oxGAwpoaGhgd69exsl3wFEhN69eyf8VWQUvcFg6BC7any8uWxb6wXBKPkk0J42NIreYDB0iHP+8TEX/+tz6huTuqyAIYkYRW8wGDrEqu16Jb5dNb4016R1nE4nU6ZMYcKECZx44olUVFS06zyPPPIIl19+eXIr14kYRW8wGJLCnH/GW1wps8jOzmbRokUsXbqU4uJi7rnnnnRXKSUYRW8wGNpNgz9irlmzc4+VBDOaAw44gM2b9fLMa9as4ZhjjmHatGkccsghfP311wC8/PLL7LfffkydOpWjjjqK7du3p7PK7ca4VxoMhnbzzY6adh13w8vLWL6lKql1GTewgN+dOL71gkAwGOSdd97hggsuAODiiy/mvvvuY/To0XzyySdcdtllvPvuuxx88MF8/PHHiAgPPvggt9xyC7fddltS650KjKI3GAztpqmiX7q5kgmDCtNUm9apr69nypQprF+/nmnTpnH00UdTU1PDggULOOOMM8LlfD493rBp0ybOPPNMtm7dSmNjY0K+65mEUfQGg6HdrNpejcshXHzoCO6du4YT7prPupuOa9UFsK0972QTstFXVlZywgkncM899zBnzhyKiopYtGjRHuV/8pOfcOWVV3LSSScxd+5crr/++pTXORkYG73BYGg3q7bXMKwkl2ElueG09ppzUklhYSF33nknt956K9nZ2QwfPpxnn30W0LNPv/rqKwAqKysZNGgQAI8++mja6ttRjKI3GAztZsnmCsYNKKC0KDuc9vW26jTWqO1MnTqVyZMn8/TTT/PEE0/w0EMPMXnyZMaPH89LL70EwPXXX88ZZ5zBIYccQklJSZpr3H6M6cZgMLSLBn+Q7VU+xvTPZ2CUos9kf/qamtivjZdffjm8/frrr+9R/uSTT+bkk0/eI33OnDnMmTMn6fXrLEyP3mAwtIuy2kYAeud6GFCUFU7PZEXfUzGK3mAwtIsyW6GPaFiK9/6DuPkw3avfVd2YzmoZ4mAUvcFgaBdV9QEARq15FHau4CzX+4wbUGB69BmIUfQGg6Fd1NuzYr0Nu3TCh3dwY8NN1FWVp7FWhngYRW8wGNpFXWOA0bKJ7LJlsM95AEyv/5A/7/4ZBAPprZwhBqPoDQZDu2jwB/mN618odw4c+NNw+hC1BVVvevWZhFH0BoOhXdQ1BimVnQSHHAwlo+DEOynPHanzapIbxyZZRIcpPuOMM6irq2v3uebMmcNzzz0HwIUXXsjy5cubLTt37lwWLFiQsIxhw4axa9eudtcxhFH0BoOhXdQ3Bugnu3EUDtAJ085jyajLAGisz8xJU9Fhij0eD/fdd19MfjDYvsVTHnzwQcaNG9dsfnsVfbIwit5gMLSLmqoKcsWHs2BgJNGbB0CgPvPDIBxyyCF88803zJ07l8MPP5xzzjmHiRMnEgwGueqqq5gxYwaTJk3i/vvvB3RohMsvv5xx48Zx/PHHs2PHjvC5Zs6cycKFCwE98WqfffZh8uTJHHnkkaxfv5777ruP22+/nSlTpvDBBx+wc+dOTj/9dGbMmMGMGTP48MMPASgrK2PWrFlMnTqVH/3oRyilknKtZmaswWBoF9U7NwIgBQPCaQ6vjnkTaGilR//atbBtSXIr1H8iHHtzm4oGAgFee+01jjnmGAA+/fRTli5dyvDhw3nggQcoLCzks88+w+fzcdBBBzFr1iy+/PJLVq5cyZIlS9i+fTvjxo3j/PPPjznvzp07ueiii5g3bx7Dhw+nvLyc4uJiLrnkEvLy8vjlL38JwDnnnMPPf/5zDj74YL799ltmz57NihUruOGGGzj44IP57W9/y//+9z8eeOCBpDSNUfQGgyFhFm+q4Ju134AHyO8fTheP7tEHfZlpugmFKQbdo7/gggtYsGAB++67bzgE8ZtvvsnixYvD9vfKykpWr17NvHnzOPvss3E6nQwcOJAjjjhij/N//PHHHHrooeFzFRcXx63H22+/HWPTr6qqorq6mnnz5vH8888DcPzxx9OrV6+kXLdR9AaDISH8QYuT7v6QUxy7dUJ+pEfvzNI9equ+ldWm2tjzTjYhG31TcnMj0TeVUtx1113Mnj07psyrr77aavhlpVSrZQAsy+Kjjz4iOzt7j7y2HJ8oxkZvMBgSYmtFA0+4/8gdnnt1QlSP3pmVD0CwsWstKxjN7Nmz+fvf/47f7wdg1apV1NbWcuihh/L0008TDAbZunUr77333h7HHnDAAbz//vusW7cOgPJy7Waan59PdXXkK2fWrFncfffd4f3Qy+fQQw/liSeeAOC1115j9+7dSbmmpCl6EVkvIktEZJGILLTTikXkLRFZbf+fnO8Qg8GQFpRS/HfRJg5yLgPAEhd488P5rixtulG+zB+MbY4LL7yQcePGsc8++zBhwgR+9KMfEQgEOPXUUxk9ejQTJ07k0ksv5bDDDtvj2D59+vDAAw9w2mmnMXnyZM4880wATjzxRF544YXwYOydd97JwoULmTRpEuPGjQt7//zud79j3rx57LPPPrz55psMGTIkKdckyRrVFZH1wHSl1K6otFuAcqXUzSJyLdBLKXVNS+eZPn26Co1eGwyGzOL1pVsJ/vsHHO/8NJJ4fWV4c8nG3Ux8aBhrx13OiO/+MebYFStWMHbs2FRVtVsTry1F5HOl1PR45TvbdHMyEFqW5VHglE6WZzAYOpGvv14Wo+St/pNj8r0eF7XKC41dt0ffHUmmolfAmyLyuYhcbKf1U0ptBbD/7xvvQBG5WEQWisjCnTt3JrFKBoMhmTg3zAegauDBrJuzCMcFb8Tke5wO6shC/F3XRt8dSabXzUFKqS0i0hd4S0S+buuBSqkHgAdAm26SWCeDwZBEiuvXExA3BRe8RIFzT/XhdTuoUVk4munRt9UrxdA87TG3J61Hr5TaYv+/A3gB2BfYLiIDAOz/dzR/BoPBkOn0829kt7cU4ih5AK/LSR1ZOOL06LOysigrK0vabM+eiFKKsrIysrKyWi8cRVJ69CKSCziUUtX29izgRuC/wHnAzfb/LyVDnsFgSD2bdtcxTG2hNn9v+jRTxutyUEM2vQJ7BgsrLS1l06ZNGPNsx8jKyqK0tDShY5JluukHvGB/krmAJ5VSr4vIZ8AzInIB8C1wRpLkGQyGFPPSgqVcJNtpGHpas2W8Lge1KgtnYM8evdvtDs8YNaSWpCh6pdRaYHKc9DLgyGTIMBgM6SNoKUYtvB6HCAXTz262nMvpwC9unMHMDFPcUzEzYw0GQ6ts37qR2epDVo44D/pPaLGshQtUgJrqCgj6U1NBQ4sYRW8wGFrF/dZ1AMiwg1otazlcBP1+8m4byva/n9TZVTO0AaPoDQZDq+zetAKAwr33nPbfFOVwoeyefL9d6VtswxDBKHqDwdAi35bV4Wms5JXg/vQv6d1qeUtcuGjfSk2GzsEoeoPBEEugEdbPB9vffenC9xksOygdPRmnow2TnRxu3BjbfCZhFL3BYIjlzevgkePhq6fAstj3s5+xU3oz+aTL23S4crrIUfVRCWaCVLoxit5gMIRZu2Ylgc8e1jvv/YmKBQ9TEtjGZ0MuRIraFjJXOdy4Jcp0U5+cmOqG9mMUvcFgAMCyFK89fQ8u5WdR/zOgciNFb/8CgEkT95gm0zyOJtNzKjYksZaG9mAUvcFgAGDT7nr2aljCGmsA12w9jGBBZJp90bgE5j063bH7FRuTVENDezGK3mDo6fgbYNc3VNb52NfxNQ0D92Olr5jJO65ng9WXBwPHUpDjafPpZA9F/22SK2xIFKPoDYaezjM/gLunwcaPKZQ6sobvz2n7DKKGHA5rvJ2FY65KKLSwOJoo+spNSa6wIVGSGY/eYDB0RVbrxUOyN34AgKPPaG45ahKDe+WweFMF931/WkKnk6YhjAP18QsaUoZR9AZDD6aqbCsF9nbOts8AyO83EpfTwc+P3qtd5wy6c8LbdcpLjnGvTDvGdGMw9GA+m/9meHvg7k/x4aZkwNAOnbPOWRjeDoi7hZKGVGEUvcHQg2lY90nM/hrnKHB0TC3sCOSGt/240MtJG9KJUfQGQw9mYO1yllrD8Cnd816RnYC/fDNs82eHt4M4zMzYDMAoeoOhJ6AULP8vBAMxaSP9q1kuI9llW+q/3J3dzAnazmZf5Bwq6l9D+jCK3mDoAXz62qPwzPfh971h0ZMABNd9QAE17Mgfx9mN13FH4DTGHvn9DsuaNnZkeFshRs9nAMbrxmDoAbz+2XL2De18+gB1r19PTsN2AspBRf9D+HZXgMezzmHhEYm5UsbjJ7Mmwsd6W1ttjKZPN6ZHbzD0ABqVM7Kz5UtyGrbjU25Obvw9EyfopQFPnTooKbKiQxnrHr1R9OnG9OgNhh5Aoz8ATTwdr8i/lTMPmsnJUwYxsk8eYwcUxD+4A1iA6dGnH6PoDYYeQA4Ne6QNLh3CDw4YBsCEQYV75CcD06PPDIyiNxh6AAUOregP991GfylnhGzlBzNndJ7AKd9j45plqKrNmB59+jE2eoOhI+z4Gmp2prsWrTK6EHzKRW3eMD6yxrNq8BmM6Z/feQJPuZdnJ/0DpQRlevRpxyh6g6Ej3Lsf6p5O7BknCVewlkZnDjedNhGA0f06UcnbOEVQGEWfCRhFbzC0k/mrdwEgXWCpPHegFp8jh5lj+nLtsXvzf8eN7XSZToc22hhFn36MojcY2snSLZXprkKb8QTraHTm4nQIlxw2kjxv5w/POcJulkbRpxuj6A2GdrK5rCrdVWgz2VYdfldu6wWTSNh0YxlFn26MojcY2smO8op0V6FNNAYsvFYdwVQreoet6G1vekP6MO6VBkOCbNpdR59NbzJ+x4fprkqbWLSxgt7Uk51flFK5Dnv5QdOjTz9G0RsMzdFYp9c77RO70tKJt7/Nl47z+GmaqpUoC9bs4ixpoLhXcUrlhnv0ZjA27RjTjcHQDIuf/i3cMwO1Y0U4TSnFaP+qNNYqcRZtrKBAGvDkds7s1+ZwGEWfMSRV0YuIU0S+FJFX7P3rRWSziCyy/45LpjyDoTPZtvoLAPzrFoTT6v1B9nOsiClX78xLab0SxaqvJod6yC1JqVw9GAtKGRt9ukm26eYKYAUQHR3pdqXUrUmWYzB0OhVKK/Dg1qXhtOqGAPs6vo4plx2sgaAfnJm5PmpR4xa90Wt4SuVqP3rTo88EktajF5FS4HjgwWSd02BIJ/lSB4DsWBZOq24IMNGxjuVWkwW0dyxPZdUSorhxq97oNSylcp0OhwlqliEk03RzB3A17OFLdbmILBaRh0WkV7wDReRiEVkoIgt37sz8uCGGnkEBWtG7d30dVlbV9T4KqOMDx3Su8l/M/g13Uau8WAvuSWdVW2T/Rtv0lHJFb8+MNROm0k5SFL2InADsUEp93iTr78BIYAqwFbgt3vFKqQeUUtOVUtP79OmTjCoZDB3CshQFUguAs7ESqjYDsHLDZhyimDVtb8695NdsozfvWlMJrl/Q0unSh7+eYwLv6e3suP2sTkO7VxrTTSaQrB79QcBJIrIeeBo4QkQeV0ptV0oFlR6N+QdEVjMzGDKZmsYABdSxWfXWCTtXopTi7tf0AG1Wfi8mDy7i3P2HUKeywAq0cLb00bDy3ciOSPMFO4GQe6Xp0KefpCh6pdSvlFKlSqlhwFnAu0qpc0VkQFSxU4GlcU9gMGQSVVupK9tMgdSx3uoPQLC2nKr6AMc6PgHAXajTjxrbjyCOjFX0S955AoCz+FPKZTtDE6aM103a6ewJU7eIyBT0O3098KNOlmcwdIj3lm/i8GfG0ztvIA5qqc8bDPXL8NVWsLmingMdemA2a8yRAOR4XARwghVMZ7Xj8vwXmxhf9hXvqclMPuCIlMvXfvQmemUmkHRFr5SaC8y1t7+f7PMbDJ3JM88+xeGAu2YLCGzotT/Uv05jbQVbKurJFx8fBcdxQE4OADkeZ8b26Ndu3MIpspkBB53DzFl7p1x+KKiZ8bpJP2ZmrMFgo5TiCOuj8L5fPPSaeio+5YKdX9Pw7ecMkl0M7Ns7XCbH4ySAE1GZp+h7lX2BQxQFow5AUmyfh5CN3njdZAJG0Ru6PZV1fl56613UN+/ohBWvwMZPY8psq2xgwetPc4a8g6W0UvQf9At6F+byhbUXjZsWccLHZ1MquxjSv2/4uByPiyBOsDLMDr17Axd8e43eHjQtLVVwOEyPPlMwit7Q7fnVC4s5+cNTkcdPo7rBD//+Hjx0NHx0L9TsgKot3P/mFxz0ySUAfJF7MLcO+hvZR1zN8N65bKeIvnXfhM8nnuzwdrbHSRDJqB799s+eh79NiiRkpTbGTQizlGDmYBS9oduzs9oX3l6zdk0k441fwa2j4a9jOX7dH8PJQ3P9/PKiOYjDwZDeOdp9MprikeHNkOnGoVI7GPvZ+nLuuu48Anfvv0feF68/Ft5+b/p9qaxWDA6zlGDGYBS9odszqiYyj2/tRy/FLTO9bj47VQFVKofto74bk1eHF4B5wYkc7n0aDvpZOM/tdIC4EFRKzTf//HAdP3G9iGuXHWBNKXj+RzDvLwz3f8Pc4GTGNzzE+MNOTVmdmuK0J0zRAffK9btqqW9s5iVqWcYs1EaMojd0a6ob/NxUc114v7ZyV3i7UTljyn7hnMwk34OUDT8pJn2E6FgxQ464kGd/coTuqkYhTtt5rTXPm6/+DZuaTh5vH9JEv1V+8jgsfhre/QOjZRMrnaP5/Pen0jc/K/4JUkBH49FblmLmrXP58ZNfxM3/6vf74/tDaUeqmBa3WH/Q4u7XvmDH63+BhtSsO2wUvaF7sW6eXiwEreT//t7qmOwxFe+Ht9cOPZPtqii8P3rCDO47dxqHjo4N53tf4ETeCu7DsEPOpiTPu4dIRxsUvWqoghcuRj10dKJXFJfi4Pbwts/vZ/2rfw3vO0Vx0GGzyHI74x2aMkJ+9O2dGlvt0+05b1Vs/CtlWVQsfo3JaiXeYE276xdY+wHcWAwbP2v3OdrD0s2VnP7x6fT9+A+wdm5KZBpFb+g2bN+xAx49EfXkmQDc+sZKHPP/GlNmX8dKdqs8ZvpuY8wP/sY/ZrzGGktP4M4u6scxE/rv4Yp43Y8vpNcF/wHXnkoewOGywxO3oOjf/XIlAKKCOqRxByn1RQaHy6tq6EV1TP6E/Wd1WEZH6ehgbFW9bie3M1ZNvfT6GxQ9f1aH6/fhK3osQ337USslk0tVnY8BUq53/PUpkWkUvaHb8OYH8wFQO3S8+NyGLfzS/SwAX1kjwuXypZ7fnXcS4vKwV/98ysnX6YXxl9qbVFrE9GHNL8O3s1Yr+PrFLzRbZs23myI7O1Y0W65NWEGmVL4X3q2pqaXADqkcJsUBzOLhdNgvzHaa0asaQoo+9sX7+eKvOlKtMJt36C+FgDMnKedrKw015ZEdo+gNhsSw6nWv1mG7OpYE9Q959ezHWGCND5dzEeTwvbUvfLbbSbnS6+Tkets3UbyECn2uV5tfRdbRsDuysyW+zblNNNbhv3k4+9VGgpXV1NaSTx0PBY4FYEfJnp446cAR6tG3U9NX1Qd42H0Lz3AN1hvXoV64hBVbq1DV2zpct6Cl6CXa7ON3pHYco7G6LLITaEiJTLM4uKHb4KutiNlXtXrgtW+/QTpMQRyGl+TygkxiNguRvL5xy7TGINnVYv6CNbu4cN3PIwll3zRfuBWqX7qK/MbYAbyGyh04RXHkvlN40jqb78xKfVybeIRmxrbXM6ay3s8xzkV656O79H/WcfzB/c8O121LRT3jZT0Afn9jh8+XCMHKrZGdFPXojaI3dBtqqnbH7DvqdM/JU9A3RtGrvY4lZAyYMKiQ8dffBtt/CAMm0R52q/wW85/+cCUH2tvVKhvPznXEt/a3Qdbyd2gqLVClB2bzCos557CT23nm5NPRpQRDpptoRn377J4FLWsPT6jWWLOzhrGizx/w1bVSOrkEd0Ve9HWVO0mF4aj7m278DZk3Pd2QdJRS1FdHKfqgH7dP20K9BX2xlH7UP8k5DDn7qZhjxeFot5IHWDflKlZYQ7AQ+PrVcHplnZ8731lN49rIoiRfq8F4V79CYNe6hOVsLK8j36rmscDRzGm8mj/n/EJn2IuiePObH0dIByHTTXuN9KHB2Ghq/HFi9gR9e6a1wrpdtTjtxfCyV76QMjdLy1Jkl0WWncxZeG9K5HZrRb+7xgd/7Eftf36c7qoYOpntVT7yrCiTRl05Xl859Y5cHJ6scI9++MC+SV+A48bvzOC3fe+g3FkCi54Ip7/z9Xb++tYqZgcjA6chM0/5M4k/ky8v2kghtZx8wESuvOzHSD897tC4Udv8czJM0UcGY9vbo9/Ti8nbuBufNLGpt8POvXZnRNHnbF+Iuv+wdtUxUa79z1ccV/9ySmRF060V/QtzPwQgd9mTZgZdN2ftzhpKqArv7961GW9jOT6P9j6x7Efd4c6Oe3xHGTe4Hyv9/WmMsr82Biymy9ec6vyQ+wIncoD6JwNtt7q+Oz5M+Jn8YPFqHKIoLOnPpNIi9p0yGYC9KvRz7swraenwlONIkntlNLmB3fid2TwbODSSGEjcxr52Vw3Z+Nhhz6OQ7Uvg+kJURz2iWmHblvXh7dv839EbKbDTd1tFv6OqgUWfzIskrJtH3dJXCHz5VPMHGbokgaDFNc8vZrDsCKctXLaagVKGq9dgANuEAA5P5yj6Cw8ZwU6KqCvbHE6r8QXY16H950/9yW28fNXx/M66KHLQgrsSkpFbsUpv9BoOgCcnD4DBjp009NsH+k/swBUkH6dDUKr9IRDi2egLrUosZzZLZ9zEr9VlOjHBHn1jwGLLmqVkiZ+iI67gLwXXhvPqlrzSrrq2lb6NkefD2WuI3qja0qkyoRsr+hXbqpmiot7Oj51EznPfw/XSJemrlKFTeH3ZNi6o+juHOpfwmUcvS7z+4xcZ5dhKbl9bKaKVhtPTOUNfg4tzUFmFuAO2y171TmobGhjn2IAqGkq/fv0oyfNy1a9vZkzDIwCUf7uszecPBC328tvPc+l0ALyeyJBu1l5HpHxN2NZwdnBmbLwefT8pR7mzueHkCYwd3EcnBhKz0V/02EJ+5voPjc5cPNO+zxFHHEut0m1ZHW8MIIn09kUUfb/BOjieVbm5ueJJo9sq+rLqBo5yfM7S3APYZftJh/FVxz/I0DVRFnNcbwJwT70OMXCR61WKqEYm6QBl2aI/753ezunRAwSdOXitej5d/g3WrWP54YLZ7O9YgUT1tPO8Ls4+cC++skbQuHtTC2eLZfO27Vztfkbv5GhbfJY76ufbZ0xSriGZODqwwpRSionr93SjLJYa/HkDARCXRycm2KN/f9VOJskaNpccCHl9mDZlCsvnrKBROfFXbm/9BB2gT2CzbpNfb8fVbwyWEupXze1UmdCNFb1/x0qGOHZSOOUkHggcH5uZJEX/yn8eoeKmvVPmC2uI5fWl29i8uxarXtvmV1iDed8/NpxfXjIDRswEwItW9C5vbqfVJ+jOxUWQTcs/xit+ClQVJVIJAybHlLv6mDHsVvlI/e5mzrQnixfphVL82X3CaV5XVCybDFT0oR797trEbej+oOKgYGwMGpVVxPZBsyg47Q4AxGW/tIOJnd9JkIFSRl32oHBartdNLdlYje2PndMaSikGBrewO6sU3FkU9xvCPGsS7sVPdLrXT7dV9HVbdTCr0r1n8NPf3MmTM9/nnkLbHS3BT73mGPLVHRT5tsKGBa0XNiSVoKW47PHPGPS3gQz7+LcAFB15JVcdE1H09aUHhc0ZWSFFn9V5XsuWR9vMs3ctjc1oYjvP8biok2yc/rYrlart6wFw/+A/4bSYHn3v0YlVNgWEYt2EgpO1BX/QYti1/+O2t1biJhATYVSmnku/i57F03eUTgjFHmpjj96yFFf+exHTZRVeCTB6n4inTY7HSS1ZWL7aNtc1UWobgxRRg8+rl6IcUpzD29Y+eOq26QVwOpFuq+gDlXqAQwoGkJfl4ZyZU+hVYE81SZKiX24N1RuPn2a8elJMdYOfveVbACZVvAVA/wGDuGzmKF4O6hAArsKB4fLZou+5q5Ns9AB49NdC/eYlsem9R+1RtNGVhzvQdqXiqLYH7AoHx6Q/GDiWV5xHQmdeVzsJzWGSBGz09X7ds73//bV4CFBLlKmtSVA5h1vv3/v2Mh6e3/q8hJrGAM9/uZlCO/SBpyQS/yjb48RSwvBNLxH878/aXN9EqGkIkCM+cOt7NaJPHpbb/sL0d+6krW6n6JVSfPHpfIobtBIgr18kM/SgtGOCRVMsS+GWqM+tTn4jG2KprPcz3fZoAQjmD0JsM00B+kfj7RVR9Fn2YCyd5F4JIF7doz/NOZ9yKYpk5PbZo2zAlYs32HZF76rZov3Ho4KVDSzMZvN+v2HvHz3a7jp3JqF49Iko+mgHHTcBaonymY/+LQPi1nkjNzxD8PX/i1lJLB7+gD55vGch2+NkiEPHRnJ+8U++eSP5K3NVN/j1l6Wt6J0OYVAfe6F5o+gT48XP17PPq8dzuu9FqhxF4HSH8yT8qde+2BbbF7+Lb42OkFhW2xhWKADUdDzQkqHtaEW/KrzvnHl1+EVeKFqB5vWKsmfbphtcnanoI8EJilVFJCPOmq2WO5csVd+mWdv3zv2GAQ1rqMgeHONZ43AIvztxPKP6thyCIV047Lom4scSsCz2dyxnmmjTTY2Kul/5A2LKOm1FP9u5kItcr7KrphVFH1Sc6XyPOz1364RoRd8kdv+oj65JoNZto9oXIIcGxBMZJxo6QD+j1dWduwBJt1P0mzZE4kjslNiZgpKgTS+ayno//Z4/Fe+/9MDu9qoGCqQWH3rkPxkR9Qxt56b/rWCaYxWVI06ASxfAPueF854JzgTA1WevcJrn5NtZ0e8EGNF5MyCDrsgPeNXIH3Kz/yye85wc1+1ROZuPYb9sw3YWrI54f2z48h0Odi6j9z6ZE8emLbSnRx+wFE97/sB/vDfglgCN0SGECwbFlHW63TH73tqW/dH9QYs/u/8RSYh66budDq5ovKzN9UyUHdUN1DQEtAkxai5HcVERAA0r34VlL3aa/G6n6L1V34a3B46ZHpPnsHsAQX/ippuP1kRFKFSKTbvrKKCOKrd+IzfUdd5ovWFPXDuXMEjKyBs3C/qNj1GmM75zJX876LOwGyLAQdOnMfbSJ5pdPCQZVFuRc48+93YKj76aAy+7P25Z5Yiv6DdX1DP+n3ux9+P7hNMOrXqFWmcRrkN+TlfC2Y5YNwErUtZNgJLi3pHMgoExZR1OT8x+ybxft3huX8DCp6JeDu7YUAoXXHYNrwVntLmubUUpxb5/fIcLH11IDr6YHn1BgXb97rPwNnj2POgkn/pup+izaiKKPvuQn8TkiT14E2hMvEc/b3WUovfXsb6sjnypw5+jQ9v6UxwBr6czNUv33pzDDtwj79SppVxx9F57pHc2AYd+vnaXTEdEuHTmSAYWNWMqktDyg5FJQf6gxYPv6y/SYqmByk0opSgM7qYiuxTsMYCuQmgpwYRMN8GIKctDAGd2lFmqSRhphys2+G5AWg7G6w9aMUtHNjXjTRxUiIvkuzmGBpgnWF+TK7GKfvCIcay0SnkraL/Y68rinaLDdD9FX72BRtzUXbtjj4iEoTgngbrE7WGrNkfdgLpyNpTVUSh1BHN0jz7gM770qaSX3zZtFA1Jb0Wi+P7xh/Pp2P+j6IfPtFpWOWylFIz06I+87X3+81EksiF15TT4LYqoxu8pSnJtU0PIdGNZbevV+4PRPfpgxCsFwBFrR3e6Yk03rtqWHSL8QQuPRH1BOWNfDCJCH4nSDQ1VJIMa2730ee/1ADiiPKQKi/uw8ax3eSh4nC2zIikym9KtFH15bSN9G9azO3soOVl7fqIXlu5NtcqmfOX8hM67oayW4Vv/F0moL2djWRX51IUnsFRuXNbxJeIMbcYdqMcvnk41xSRKQbaHfc+8Bsnt3XrhsOkm0qP/trwuPJAMUFW2lQvuepEJjvXUOjNzwLU1Qop+3uqdrRdGz48I4SYAnua/YpqabrKr1rTo5twYsPDiZ1fp0XBO/JdxaHwH4No/3URDY9vnADRHTYMehA3h8Ma6ws4c0wdHjvamCtSW0xl0K0V/30tzmen4kpxB4+Pmjy3tzXI1lOyypXHz47F0cyWX3foIf3E/EEmsK6esTPfwQz364asfoe6+ownWJ6cXkCkEghb/mLeWslY8GlKN26rH78gcJZ8wTrt3GmWjH8ROfuWKBN1bsPhrflhxjy6213EprV6yCJlu5vzzs9aKArrXHcItQZzZe3oshXA1GYx1N1ZCbfMvlMagVvSNBcNgr9lxy0w99ecc7bsFgJsd99LwYcfjxdf4AkxyrA3vO5uY4FxOBwdOGssn1t68t65zLAPdRtGX1zZy1NfXAZA/+uC4ZfI8LpZbQymsXt3mxUhOuGs+l7peiklbuW4DJVU6IFUwJ2I3zLGq+eT+H9PQkJp1IFPBIwvW0+utK7D+MhpVtbX1A1KE22og4Og8V8lOJ9SjD0Z69I94buE456fh/V7bF3C083OC+1/OxKN/kOoaJgU3QcbJhjaXDzQx8RQMsCc1Ofa0vzft0QPQTFgJpRQ+fxAvjWH/+3icMX0wBQMj4zuubYtar3Qr1DcG2UdWh/ebKnqAH87ejx2nv8Bhx57ZYXnx6DaK/v+e+5KJso4tQ06E/S6OWybX62S5Goo7WA+727bCzyzHZxzr+JSPrbH8cz9tvin84Hr+5bkZgGpH5JP6kcAsDqz4L9sf+2EHryZzeGbhRr7jnEcfqaTi9T+kuzqA/gR3Ww0EnKld1DmpRHndKKUYdu3/6CMV4Wy/cjKtUs/4dR58RRoqmBwOcy7GIYox8m3rhYFgkw5YVu+hcMLtcOlHe5SNdq+sCy3O2Ewcq33/9A4XPfIxTlFh//vmcHoi+cEkTHj3BxVTHRFF7/LuKT/X6+LEyQPxuDpHJXcbRX/LTC/Z0kjJlOObLeNyOljrGKZ3ti3RNvXqlqPVzfIuo9GVy/7Xvsq5R84giIP+onsNtWNOwzvyEADWDTqRQ674J+8Gp9BrZ9s+U7sCu6NMNipDlmRcvKmCbHw4s7qWF0oMoYHAoJ9qX4BDHV9RZNvngzjYQREugjTiiTuztqsx1dG2BdH9TTVrdhFMPx/67OlF5XJFevQBr7ZxV1fEeq0opVi1vZqd1T5Gi3ZdzM5v3hwEsZOnmn5htAe/ZTHV8Q3fFh/IvL7n4t0r9Yu3J3VxcBFxAguBzUqpE0SkGPg3MAxYD3xXKdX2kH0JUFCu7e6ewdNaLFeWPYJgo4OabxZQ+Ox51BXuRc7Pm1fMRcFyarL6kp1TjBtQZz6Gyh+AlE4nF5gEfHv5ZoYVZyMOJ59kjyK3cUm7FizORDzBSA/JkSGzf+et2smB0kBObkHrhTMUiZowta2ygYuckcH+ak8/yhqyGCRlVLl7U5JhceY7k0BTRe9uPoaPyxn5fRX49LPpfuXHMCHyUnn4hdc4atEV/M09ipOdOvhgTlFsKIWmnD6tlPoNHrKlkd7fPA++O8Hb/sHwQMCiRKrYPnQGh558Y7vP0xGSrYmuAKJdT64F3lFKjQbesfc7h93rwZMfN4BUNCfPGMkaawB1i14AIKdyVdxyQUsxb8k6jnIspNEd6QHI2BOR0tiJWENK8hDb9SuQXYKTYKe5SaWKm1/7mre+XE0ff+SLx13Vts/vziRoKe589xuGOstwF2eOa2XC2DbnRr+PHVU+8iUyCFef3Z9dSj9zlQWZF364PQRwtl4I3fuNoYXYRNEeOlaW7tG7fbH9yNVffchQx46wkgdwDtm3xTqcNHkgm2b8KpKwomOrTgXtIIriijOmkCKSpuhFpBQ4HngwKvlkIBRx6VHglGTJ24MjroNffN1qL/r8g4azSg1mgGrZ5/ah+Wt58qlHAPBMPKXN1XBk2W/+ToxrnSyufu4r3lsZvx2eev8rjn5pOi+69QM/Pzgeb+3mtEfp3FJRz/nO1/T96xffu6pLYPfo5z32ey566H2mONZQpXTvtao4av7HkP3TUbukY6m2fZX4mrozttCj90V56FRd8gUrrVI2lhzG3JU7qLt3Jrz7R9xWxDFiW/EMuL4Seg1rtR6DZv2UWb4/650XL+nQcx8M6AF3RxO//1SSzB79HcDVQPQruZ9SaiuA/X/fOMchIheLyEIRWbhzZ9v8bePShpmDhTludqvWy+3evpHfux8mmNuPPkdc3vY6hHog/szzvNlYXsdBN7/Lul21LNtSyasLV/HFY7+C7bFL2imluKyJp9H71mRcwXqo6dwVeFpjY1ktl7r+S0X/A2C/S9Nal46wqVIHWTsq8D6LvNp5oHzQTJ4uvY7qg/+PXnYo3X6jpzd7jq5EW41Pjf4mywe20KNvDERUjTenEB9u6urruPKf75Cz40uYdwu9PZGZrjn+tluNczwuLjnjhEhCRfu/Zi07iKLDmT534KQoehE5AdihlPq8PccrpR5QSk1XSk3v06fzB55qomJcB5v5pBxct4I+UoXztPv3mEHXEh0JnNbZrC+rZXNFPe+s2M6P732JpVkX8gv3c/g+jA3JunxLJT9y/S8mbWevqQBY69O7yMrmXeV69uKIw/eIVdKV6L9XJKaK156t2Ssvm7MuvAq3J4vNqgSAvL7D0lG9pCPSth5xY9PwJC306McNKGCNNYD1o87D63Lgw015ZRUHOiIdFy8RZ4KW3CrjcfiYvlzv126t/12wOO5i5W3B8mtFL92gR38QcJKIrAeeBo4QkceB7SIyAMD+P+OCtjc6mrn5oYkseXE/QppFQj2QDFT0IZvm7W+t4gC1KJz++pff8OqSiI/8H++JDcQVEDcH7adNCOXb02unLyvTMYfyC4tbKZnZnHvEPvw8/9aYNIc9zjOqbx6vD7uWrbPug5LMWzmqPYQiWFY3+NlW2fxvw+9rkudo3rY/uDiHkTd+zbBz78ThEAQ42LmM7zrnAlDlHYDHaiCohDsDp7DlyHsSqnOvXA9T9tceMi9/+AV/+O+SVo6IT9Be6tDZ1W30SqlfKaVKlVLDgLOAd5VS5wL/BULxY88DXmrmFCkl237Lr3MMwaGaCWIUUvRxJmq0RFjRZ+A6spZtZxzsX8d4WR9O70U1H36jFejC9eWUEBsLaEvRdHoV2VO069M79hCo115ALc2Y7CoUj9gnZt9pB+nK9bq4+4LDGXDg2emoVqcQUvTH3PEB+9/0TrPlAtHBAad+PyEZofUJDnVqhezyV+FRDfidORx00R2MGT8lsUoD3r6jaVRO/uH5K99f3z5fklCP3tHVFX0L3AwcLSKrgaPt/bTT58Tf8erwX/GFd9/WFb20zVsgRChwWrAx86JZhsauXvdey7mudwiKm3nBiRzqXMJxm+4A4JN15UxwrAeg6rz3WLfvDfS74Emys7NpVE6Cvhp2VvtiPB5SiQoFmuqAu1um8NNjJnHT+Jf5nV/3hRwJdiq6EiEb/eaKljtAQbtHb51yH5x8d7vlLcg6jByrllyrloAzi2lDe7V+UByK+wzgpeBBAEys+4Sv/3ZywkuRWvbsZ4e7Gyl6pdRcpdQJ9naZUupIpdRo+//OidiTIMfvN4HjzrsWS1w4aSZoUegF0MKnYzwc9qy6TIxm2VQ5OwdPpwptAz2o7DmUUqz/8N+c5XwPhhxAwfB9GH7cz/DmFZPjcVJHFnW1Vcz449v89a2V8UR0PqGZj91A0Rdmu/nVGYcitqeY05nYs9YVmHfwY0Db143124tzOzo4/rI5Vy8S348yAs2ZZ9vA8D65fGyNC+/vvXuunmyZAMrfTUw3XRXL4caBih/3xgop+sR6WYEcPRkjWNa2EAupxGrqInbsLfiIDBC9t3wLfwncQoHUwZADYormeFzUkoWvVveoX1+anslT0th9FH2IC046CgBX6dQ01yT51OXouQ5tUfS+QJDNu2zPmHYs+XjbqEfC2435ehH1EbKFgLP9MZH65mfF/EYAKhqCDLv2fzz9advGq6xgyHTTxb1uuipK9owgGELaaaN3F/RlvdUPNi/saPWSju7RKyycrB78XRgwiYCKXN/D/3s/UnjoQTHH5nicVKlcPL4yJshaBljpCXDm9Hc/RT94xgnwow+Qfbpm4LIWcWijjaMVRX/XO6sZc93rLNtg+2u0QymuVpEJdH1tt9QBUt7hmEiXHhEbfmFXuTZMPNWCot9R1cBce45KXb02RzWNtplKerSiDytxa0+3KWmn6aYo280iNRL31nZ5mnYqllLk0oCDIKP3ngjouCohHq+L8ksfsl/MscW5Hjaofoyo/Jj7Pbfzi4b22087gmoIKfquG/4gLgMmxV1btrsQ6tEf7VjI+qxzIGqN5QZ/kNve0gOpWRJaxD1x5ZzjcbLK0uvK5pYMDqcHXc27aLaF8YNi7fvKNh+2FAfn1Dve5qt/Xc27SzeyfmcFEBX2Ig30aEVvhRV9pEf/ydoyVq9czuk77TjUCfboe+W6WWyNxF23HWo6MPmrEwhaKjwRh2z98AbjPAIV53+4R4851+viA2siLiwGSRkTAit4fkHHF1p5a/l2/j53TZvL++ttj6Bu1KPvzojEPl/nOG2Pm62Lw2nVDZHfX9jjqx2B3H574jg+m/Uf1FVryc/No1bprwLVjpdGDE2OD9ZXcaJjAWMbm7fVf7fxP1zheoG5T/2FdVvtQGstzAnobHq0og971FgRz5uLHnib0U8dgBu7l59gj74418tOO04J9Rkx9hwmaCmKsHvE9sLZTe2Pb5z8BUVDJsQ9/ung4eFttwTZ743jmbd8I5+ua/91XvTYQj5780m4cypvfLqUF/91Z7PTzSvr/XgCtQTFnVErSxmaJzTQHOrR++04ije+9FV4ib0nPtkAKKbKagaJvTZz4aCEZRXlePjewWOR3N4UZrupth0NivoN7dhFjIyNNtlYV8Vdnru5teZXza5rkYd2xnATjKwuZRR9elBxevSXuJoEMEqwRz+4VzZ1Dnudy4bE16btTCylwqFwQz366FnCn+53J7Onjmz2+Ctnj2ODFZlANkjKWPPkL9j28DkdutaHPbdC+VrUyz/jlDW/gW/ejltu8+568qgn4O7C4Yl7HA7735Ci1x2nrbur+Wy97iDc8fZqDncs4gXv7zjJuYBgQWmLoQ/aQr9CL3cFTuWt7GPJm/XrDp0Lh5N5I38Z3vVHryLXzLPqtBcZD+IIz9sxij5dhBdojtjoe1MVv0wbcTkd5BbYa4ZmmKIPWnpyFADZukdfrfQPavPeF7Dvsec1d2iYPwW+F7P/Q9cbnOT8COuZOTFfRm2lVCLmrSLbrKSaxN4JsbminjypN2abLkRo2CHUow+FHHETxB0VgHCUHSt+L8dmZFDH4/t4XU5+du3N7H/Fv6BgQIfPd+i51zH/9M+xlLBkzWYalP0lvCT+2rMuW9EXUMcgsU03HqPo00IwtObo1q/C5oJ8VyP1KsrfNcEJUwC9S3SckoxT9EqFlWnIdPOsOooXggeRf9QvWzhSU5Dt5g1rBq+dtoKj7HU1QzjWvgubEvM02lXj4wzn3PB+6BPXXx5/6blNu+vIox5ndjcbiO3GiK3pm5puXARw2h45o2QTl7teDB/jGJycQG598r3kZyVpAFQEb34xtWSR79tKlujOodoVf0EVpx3b8Ur3c1zt/rdO7OBXSkfo0Yp+dYHtWfL02ah39TJ5HquRLap3pFCCNnqAAX20oveHPEQyBMtSFGEr+qwiAGZOHM7P/T/GXdDyYgwAZ88YzEs/PohjJw3EO2AcVzReBhDp3dSVtXD0nmzaXc+EqFAMkxx67kGwKn6EzB3VPgqlzij6roTdURL0GJFf6f2Rji3M//gjlrz/PG97r6ZQomaSJ6FH3xnkeJzUkM3pzg/Caf5d8R0JQj36GIzpJj306z+I3/vPBaB26f+wLIVH+aiNWge2PS5vJb20/bu2JrNi0oe8bpQnD+xZen85YxLvXzWTbE/rLzSX08HkwUUA/O+nh/CqtT8vBg/kjryf6QIJLrays9rHQCmjUsX+AIL27Mim1PkCDHDsRvIHJiTHkD7EEerRWwQsK2y6+bHrv1y1+ntMfC/O+sqDW14YJF3kelyUq4hu2K6K8Pir2Lpk7h5lVZPAzMH8QWl1IOjRiv70aaW8UXA6rwb3JdhQg88fJEsaKS7qWI/Rna0HC4O+zFL0llIUSg0qK+IX7HU5Gdo7t13nu3DmGHYcfTflAw7VCXWJed/sqG6gt1SxWUVc6ZZbQ5tV9A0+HwPYBb066EVhSCES/jcQVDS2ZfXSdnxFp4LeeR52qKLw/ib7uR3wn5NhZ+xKdVYTRe848fZOr19L9GhFP6Awmw+uPpxPZQKF9RsJrH6HbHxY7Zh+HY3Xm01QCcGG+AorXQQtRS9qUDnJCfF7zTF7c/GhIxnYVz/w/voqNm/eSMXbf4W3fgetBHbbWe0jj3p83kh9dqkCLF/84zz12/UncZFR9F2NE5wfEWioxerCKifP62KDipg41+RGQlasXLU8pmy0oq888FfIXrM7v4It0HVbPUmICB8VHMduZwny+cNk04jTk8Opvhv4k799YWKzPC7q8WJlWATLQGjCVHb7Ivk1x4h+hdQpL1VVu3nu77+haP4N8OEdsPHj5g+q3IRzx1JyxEcwKzImUkUOVmMdv//1ZSx67CqwV+cByK/TnhmmR9+FsCdMTXGsxfPOdbiaCyLYBRARdg45Prx/2IV/Ds+Z+ei1J2LKRod8yO+dflNjj1f0AGMGlfBRcG8c274iSxpxZ+UwcMKhcNAV7TpftsdJPd6MWzfWshSFJF/Rl+R6qCWLQH01/Ygs16aaedF988V7cPt4frJK22et3IhvfqN4Uf46fuN+gilrH4hxX8ut36Q3TI++yxBjwqjaijveIKXNdf4f8sE+d3R+pTrAVRdpF+QtI79Lv97FPHfo6wDMcb2JWvlauJxbIteZzjj0IbpvAOwE+NFhI/h0RT5WXQVZuPFk53HPGfu0fmAzZLud7FZ5FGbazFile/SS07v1wgmQ43VRq7LI8tVSIlXUKw/Z0kjAV0dT57b5y9Zx8H9PiUmzikeCHfqk2t2HXoH5kcwqHTyt1hdA7d6A5XTgKCxNav0NnUiUM0MAwR2nR7/ONQKOv50/TJ2Zunq1FxH4TRkD7XGEMYMiv6XAitdwjzkWIPY6+45NaRXjYXr0wPiBhWRl55NNA9n4yM7t2IScLLeTnaoIV/2uJNUwOahggEJqkeyipJ43FKseXw19pJLNaJt9VVUV5bWNMWW3rv96j+MDQw7mgcDxPNTrZ8wvPCHsgwyAHZZ47c5aStmOL6c/pDE4lCExJKpHH1AO3LKnou9/+CUMnzozdZXqKE5X+AU2dkABHwR1yBDZEOmguAmw0irluIL/wIDJaalmNEbR2wRc2ThFkSs+3N6O+bv2yfNSRkHGKXqXvxqHqOT36D1OashCNdZQTBU7nP0BuPONxezz+7diykpQT4p6NbgvbwX34el9nsDZZzR/CnyPefnHowoH41MRRV5bXQHAmh3VjJVvUb2GJ7Xuhs5FSayij+dfnrX3UamsUlLpX5DFBf6reCJwJM7KDaAUSincBHB5vDz+o0PTXUXAKPowQWeUcu/gDLaCbBf1koMjkFmDsa7GCr2RJK+bEDkeF3UqC+WroUQqqfTqKeeTHWv4s+sBeGg27NazXa1GregPP/dXlJ/0KKcceyzTh/XiBwcM5Q+nTKBvQVbMZ2/u4kfBsti4fhVjHJvwjDs2qXU3dDbRphsHniammxeyTkV6Nx9fKdMREa45YTLrVH+9hoWvCkvpEA+52dkU56bfPg9G0Yex3MlT9CKC5c7FHcwsRe/2VeiNJA/Ghnr0Wb5dZEsjDTla0Z/mnM+Zrrna+2bpcwBYfh3gKTs7lzNnDCHL7cTtdHDjyRMYXJzDgSN745DY6JWNXz3H5iV6NqJrWOyCKIZMJ6LoLRx72OhPvfSPqa5Q0vnBAUOpc9pzb+rKaQxYuAlgOTLHxGgUvU3QHTVpqHBw8wXbiN+Zg8dqaDaMaTpw++2AbXb4g2ThdTlowEtxwF4dKK9fbLwgALt9ld8O2dqMJ8Jhe/VhkyqJSfO8dBE3q7/qH07/iUmtu6FzUVHx6IPxTDftCEecabidDnr3sx0EqrdR1xjALYG0LjTSFKPobXzeKOUyeL/mC7aRgCtH+9IGMmeRcJffnsCV5OiPIsKpjkj8j/ziAdTTRJHX6fEKK6zo4y8GkZ/l5oNDnuCRsQ/skRfIG2gGYrsY0QuPBHDgiTMY2x3IK9ULiFs7vqauMYibAOLMDLMNGEUfxp8T8eUmv/UAX60RXr6saRgEX/oCnbkCnaPoAZ51RmznvfsN0vMIoqnV4YhVwI7N3ULcj7OP2p/vnHJ6eP/BgD63yilp7hBDhhJthAsqbbqpUukL7tVZ5NhLF9ZXbKOurpo8GpAM8J8PYRS9jSoawrdWHz7v/92knK/eYw943j4O3rxOb3/xGNxUCuVrkyIjfM6HZjcfbmDdPFg7FwI+nGFFn/yFO66tOze87S3qT4NtullqDWOFNZhv1q3XmQG7R+9sOcBTblSQtS22KUdykju2YEgtAQQXQXb2mtp64S5GSUEe9cpDffVuRj88nlGOLRkxUSqEmTBlk5OVxczG27mgdATTknC+iizbZmcFYMFd+i9E1RYoHpEEKcB/f2IL3BB/YsajJ4Y384vO1Buezl24w5XfJ9yj363yEBRZu7YA4G+wX0itrOMpIiyyRjLFsYYG2wzkzE2uW6ghtQSUEzcBsrOyuKvf7znugCl0XX+bWPKz9NKFqr4Sh6Vj1WeSojc9epvCbLf2CnAlJ3JeTU4LA7qv/yrSqw/64U+l8NXTHRNYtucCCL5A7MDX7Ip/s8waqid8JJmCLBfH+G7m2d6X4PFmh5XzZlVCGYUM8eqviUAoMqWn9YiZ5zT+moMa/kZpnjYAOEyPvksTUKJDIDg9/OTSnzJySmb4mCeDXK+TapVNY00kBIjTbRR9xnHq1EFcOnMkZ+87JCnnc2blUa5iTSSLLXuyz7bF8OpVert2p579+eZvEpaxdMOOyM6/z90jv2b1gj3SBkct3ZdMfjl7DF+rISwc8D2y3E6WWsMAKB43E5+nmPxgBQDKV4uFs02xuc8/fAKXnnI4Rw7VA7DJnuhlSC3avzwQWau5G5HndbGLQorKvwqnOU2PPvPIcju55pi9GVycnIGiLLeTMjuyXYiLGn8R2cnXs0dpbHsPtylvvDe3xXz/Lv3V8Gjg6HCas4WgUh2hukF7UxTluPG6HFwfmMOwhicZNPN8qpxFZFu1NFTvZm9rNX5ndpsWdPnl7DGcu/9Qxkw/UicMP6xT6m7oPCTqPk/b+hROsRJeh7krkOt1sd7qT75vWzjNbTWksUaxGEXfSWS5ndQSsUNXqhy2U8xM321YSqgI6Ld9XbUOfGa1Q9GX1DSJG2MHAAvxzld6ab5ngjPDaU1XvkkWpb30JLOpQ3qR5Y6Yv8YNKKDGWQSA/43fcKhzCd5gglE995oN12yAIR13ezWkFwdWjG99d6Ew2839wRNi0sLzVjKA7tfiGUK228lv/XPC+4VSx3enl7JeDWALvQnWVwDw73lLAKgIJO4fPqB+NdUqm9N81+uEzZ/H5G/YqnsX0Wvglg2elbCctnDS5IG88pODOWZCf7yuyGMlItS6tG197eIP2y8gyYHYDOnBiRWOUd+dyPW6uPyMYxnT8Ag/b7wUAEeCS2t2Jt2vxTOEbLeTxWok+zXcHU7z2gO91So77E9fXqbt7OJJ3OUxL1DONlXMMjWMAE7YvDAmf3xvB5YSdpPPyb4bmem7jWXT/9DeS2oREWHCIG2qcjiE644fy2tXHAJAnVu7mg4X/eL59pBbOqUOhszHgcrYpQI7yilTBuHDw3Kl10uQhso01yiCUfSdRJbtB76DonDaWftqTxwfnnAoALcdhrfF5QstS/vL+2Ntfp5gHbVk4cPDducAKF8Xk+9orKbekcOcA4fzlRrFejUAr7dlt8ZkceEhIxg7QMf/2JozmlrJpUDqWGoNw5q858CxoWfgwIqZLdudcDiEFy47kN2hBcRNj777c8CIYnrnelA4eCc4lfrDfsv4gYW8feVh2vXQr0MjZAW1ovc7WxgEXva89pefH7vAsNeqw5FlP1Te/D1WtHL4a2h05uJ0REUQtGIDhqUCtzeb950HANCIK2kD3oauhwOFku7Zowc9RrWLQj63RsPJ96a7OmGSouhFJEtEPhWRr0RkmYjcYKdfLyKbRWSR/XdcMuR1BUb1zefz32hvlwv8V5E180pALzPYoDyIPUM0x9KKPkgLD3+VvVZqE0WepepwevMoyfPQ4MjRvvkqosjdgRr87jwOHh0JHeBxpf7dvqPax/v12rW0NNeKefEYehbd1UYfjYWD0xtvgL06ZzysPSTLz8kHHKGUqhERNzBfREILKN6ulLo1SXK6HL8/eTwfrysPu5nluJ004MER1BMrsi3bvTLY2NwpIvFxvAUxydmqgTp3LgXKjcNfCzVr4Y1fw1G/w7rvEGbJSra5J3H4mL4su2E2y7ZUMWNY6icdVdT52aV03T0Z5HJmSC2V5OEgCI7uregzkaS0uNKEuptu+y/1NoIM5PsHDOOecyLrz3pcDny4cdgrLeXYpptBG1+Gj+6Je45gve2m1cQFM0fVE3TnMaR3Djn+Mp348T2wbh6OXSv1vh3XJtfrYt/hxTF+zanisfP3ZZc9pyArUddKQ7dBlEW+1Hf7Hj1AflZmzRVIWouLiFNEFgE7gLeUUp/YWZeLyGIReVhE4nYnReRiEVkoIgt37uycmZuZgtfloEF5cAZ98NmDTJSo0AVfPh73mM9X6dWZGvyRXr8/aJFLA5Y7lxElefzGfz5qwnd05pLnwuV27nV28i8iQQYX57DVq2P7VLUUGsLQrSkQHecoq3ZrKyW7NstvnM2n/5dZyyMmTdErpYJKqSlAKbCviEwA/g6MBKYAW4Hbmjn2AaXUdKXU9D59+iSrShmJy+mgHi95jTvhf7+gVKLWle07Lu4xFRV6UlXQF4lt39DQgFf84M5jRJ9c3vRPZssRd+jMxZG4OdbeJyX9GtpDXl4+p/huZN60u1ovbOg2xPt+DC9p2U3J8bjI9mTWgHPSv6GUUhXAXOAYpdR2+wVgAf8A9k22vK7IV44x8TOamR1bqLTpxmqMKHr15b8AyMLHiD76uOtfWRlz3DX+i+idlxnxNopzPSxSoyCv47H+DV0by2W8rlJNsrxu+ohIkb2dDRwFfC0iA6KKnQosTYa8rs5cx4H4HJGH/Y/+c/SGv0lM+frd8ORZjJf1AKioCRhZXz4MQKFvMyP7aDv8W8u3xxz+7+BMeue2HjwsFYQWSU6H148hw+gBNvpMI1kjBgOAR0XEiX55PKOUekVE/iUiU9ADs+uBHyVJXpfG5Xbzp71eYEDFFzy2JpctlHCacz5jmy4esvhZWPUaefb3r3vnsnBW7YD98ZR9zTeTfsnM/IgyLyueysaGHC7ffQYgGfMJeeEhI1i5vZpxAwpaL2zoNsTzyBDjp5FykqLolVKLgT2WjVFKfT8Z5+9ueJwOHv28DBgaTqvDC6E1XUMEfeHNd4NTmLlrqY5f73Sj6qvYrHpD0VBEhMsPH8Xd733Dnwf+jcWbKtmk0rdkYTz2HV7M+1cdnu5qGDIAo+hTj/mGSgNed2yzHzW2Hw14I8sBrn4bHj8dFmrzzMSGB3kxeDCOoA/WvAtA1q4lrLJKw5Eifzl7DNOG9uKZhZv4eptW8v0KMsNsYzBEYxR96jGKPg30jTK1jCjJZfqwXtQqL1ZoIfEnTodv3obytdSUTKaaHD6x9tZ5a96FunJyKlfzmbU3OVGmmUmlsfHvj5s4AIMhnQgwpuER7gqcEpVqFH2qMYo+DUwcFFHIvoBFnzwvdXhx7FzO1vLYGNav7f0nALZTTKO3NwR8qM8eAuAza0yMDX5yaVF4+zvTSvn1cXHWkDUYUowPD34VsRKLstJYm56JUfRp4MeHj2LOgcMAOGe/IZTke5ksawBYc1/sBKer3o542gQdbgj6qV35HkElLFKjokPbMH5gZKDz+/sPxeU0t9eQXkb21R5hwShVYyIdpZ7MmqfbQyjK8XD9SeO57vixOB3Ciq3VDBQdwuDgxvl7lPe6HPgCFkFxg+WH8nX81zqQmeMGMapvJI796H753HfuNMYOyGdo78RXrDIYks3wklyW3TCbe258KZJoevQpx3T50ojL6UBE6JPv5YEmy5BFs7ftkhgUJwQbyfLtYocq4p5z9tkjEuQxE/obJW/IKHK9rpgBWDMYm3qMos8AeuW4uS3wXZ4MHAHARis2DMQ1s/VM2gBOaKjEpRqplgIz+cjQZciVSNRSo+hTj9EUGUDIlr5O9QegjPxw3ju/OIwDRuo1X7dUBwlU6eX46t1Fqa2kwdABcogOT20Ufaoxij6DWKe0O6QXPwCbVR9G9skLhxYO4CJYpcMc+D2F8U9iMGQgHvuZBuN1kw6Mos8gFlp7AfC5tRfnNP4fT03+ZzjvjZ8dSiMuvD49aJtT1DctdTQY2oNXohS96dGnHON1k0FUkM/h/r+xJViIDw8TsyNLAHpdDgIq4jPfr5+ZDGXoOngJhLerR59Kdhrr0hMxPfoMY12wDz50pEeJ8jh2OgTL3g8qYdjQ4Wmpn8HQHkKmm8saf0rF2HPSXJueh1H0XQS308E4h15p6tbAmeQXm7juhq6D2+7R1+OlIWBs9KnGKPoM4cEfTA9vxwtG5nRI2Lb5hjWdopzMWFDEYGgLHlvR+3HhM4o+5RhFnyFMjApI1stW4h5nxHTjdgpnN17HS65ZrFf96Z1rFL2h67AT/XxXqFxG9clrpbQh2ZjB2AzBGzX56UeHjeCrjZVcdOiIcJrTIaxUQ7iiZg65HidFOe50VNNgaBfX+c/nveAUXrnpJ+muSo/E9OgzBK8r4lFTkufl+pPGk58VUeYuR+RWDS7OCfvWGwxdgRpyeMk6ON3V6LGYHn2GkOV2MGNYL1wOR0wY4xCuKDPO4GKzuLKha/HTI0ezcH15uqvRYzGKPkMQEZ695MBm851RPfjBvYyiN3Qtrjx6r3RXoUdjTDddBIcjukdvppsYDIa2YxR9F2R03/zWCxkMBoONUfRdkGlDe6W7CgaDoQthFH0XJHqdWIPBYGgNMxjbhZg5pg/1jcF0V8NgMHQxjKLvQvxzzgzjP28wGBLGmG66EEbJGwyG9mAUvcFgMHRzjKI3GAyGbo5R9AaDwdDNMYreYDAYujlG0RsMBkM3xyh6g8Fg6OaIUirddYhBRHYCGxI4pATY1UnVMbIzS3ZPvOaeKrsnXnNHZQ9VSvWJl5Fxij5RRGShUmp66yWN7K4uuydec0+V3ROvuTNlG9ONwWAwdHOMojcYDIZuTndQ9A8Y2T1Gdk+85p4quydec6fJ7vI2eoPBYDC0THfo0RsMBoOhBYyiNxgMhm5Ol1D0YuLzphTT3qnFtHfq6Wlt3iUUPRBeDTvVNyhdD4SIzBSRuJMfUoBp79TS49rblm3aPEVktKIXkaNFZD5wq4hcDaBSNHosIieLyKPA5FTIi5J7jIjMA74H+FIs27R3amX3uPa2ZZs2TzVKqYz8A0qBD4ET0W/f/wF/tvOkk2SGvJAOBxYDnwOXAr06+VoF/dI9G6gCzjDtbdq7u7S3afP0tHn0X0b16Jt80uwNLFFKvayUqgbuAX4uIqOVUirZnz8iIsq+I8A6YDZwFbAfMCmZsuLJVUpZwBbgMeAbO+8MESkVEXeobLJlR+2a9jbt3SmYNgdS3OZNyRhFLyKXA8+LyM9FpABYBRwsIgfYRfoCy4DrOll2f6XUeqXUVqXUu8B24DARGdSJcq8UkRJgPvqt/3cR+Rr4LnAXcG/okE6QbdrbtHentHcT2abNU9TmcUnl50MLnzenAp+hP2/+Cfwd6AdcADyC/tx6EhgOfAUM60TZdwNTovInAY8DpzU5rkOfenHk3gOMAQYCNwFT7XLFwE5gmmlv095dpb1Nm6enzZutU2edOMGGuRk4394eClwN3Gfvu4F97W0n8A+guBNl/wJ4uEmZK4DfAkcA13SS3KuAB+39rCZl/wEcZtrbtHdXaW/T5ulp8+b+0mq6ibKJrQXOAVBKbQD+C/QSkVOVUn6l1Kd2ud8DuUB1J8r+H5ArIidFFX8KuBD4NzpedLttiS3IfRnIF5GTlFINUeV/A4wHvm6PvDbKTnp7N22fVLV3AnKT3t4JyO427Z2g7G7V5i3UJaU6pS2kVNGLyFEiMi20r+xXG/AcUCciJ9v7W4G56M88RGS0iLwETAB+rpTyt0N2YdS2tEH2ONHkAX8DlgCTlFJXNal70uXaZQ8RkfeAvYDTlVLbE7zk9shOWnsDruidVLV3e+RCctq7HbKT2d7uBGUnq73bJRuS1uaJyk5mmyMizgRkJ7PNEyIlil5EporIa8ALwKio9NAbbLedd6mtkCqBPCDLzt8G/FgpdVKiD4OI7Gff0H+IyPki4lVKqagb1Kxsu+EbgCuUUscrpbamQG62nb/evubvJyK3o9ds53ekvfcXkSeAG+wfk9NODynBzmrv9spNRnu3+5rt/I609wEi8izwFxEZl6r27qDsZLR5u6/bzu9om98IoJQKRqW3qs862ubtpVMVvYg4ReQBtA3sAfTgx1g7zxX1BssG3kC/+R4QkYHAVMAPoJSqVkptaof8SegBoOfsvyOwXzRRN6g12QGl1I4Uym20y21USi1P0zW3t70noD0oXgF2ABcDP7DPGWij7Pa0d0fkdrS9k3HN7W3vvuiBvleBMrTd9/wEZSfc3kmQ3dE2T8Z1t7fNzwMeBa4Tke/aaS77nG3VZ+1q8w6hOnkQADgNyLa3ZwPvEzUQA1xvN8pU9Oj7H9CfOfcCzg7K/iHwtL3dC6348olMYvh9Z8hOl9wMkH0h8C97Oxe4AXgbGNHJ7Z0WuRkg+2jgqSjZs9EvnL3ttD8Y2UmXfRR64tUs4NuodKf9//WdJbtD9U76CeEwYL846WI3UniEG+3H+iQwsknZnGTIts/vA/4IbAI+Bh4Gfon+hHsSGNVR2emSm4GyJ9sP9Sh7/3foF80N9g8yKfc6XXIzQPYpwP8Bx9v7fYDVofOjFcvvgD8DOUZ2UmWfYO87Abe9PR/4fVTZpOqzZP4l70S61/g8UI5WLL3sdCHSmyxFj0gPjHO8I9my7by97QfgB/b+YehPvn06KjtdcjNQdujFnQfcAswDXkT3ss4Cbo2Wl8T2ToncDJDdxz73POAStInoO3bezcAdIRnAwTRxFzSykyb7VDvPY/8/HqgE+sU5vt2yO+MvmTb6RuBd4Fz0NOczQNutlFJKRBxK28Q+Ab4TfaCdZyVbti3/a7TiC9njPrfLSBJkp0tuRspWStUopa4GLgf+qZQ6AT3VfXxIXme0dwrkplv2SOBDpdShSqn70H7ZV9p5TwF7i8hRtowy9MQgn5GddNkh75hGEXEqpZYBz6JfOojIsaGDOyg7+XTkLYEedDoMKLL3swCPnf4AsFf02w3tfnYjcEFH31BtlW3n/Rg9NiBom+rHwNCuJLcryW5y3NXoz+p2zfpLl9wMkT0TbYpwY/ca0aaDacA/7H0HMAdYih50vxztr15kZCdd9v32vhD7tWahPW2uJcN68qG/hNeMtV2I+qNtURawBm2LvEIptcsuMxo4D2hQSv3BTnMopSwRuR2oUUr9JiHBicv2KaV+b6dlo3+Yfe2b9lOVwGh/uuR2Mdnhe22nTwNuA4LAxUqpNZkuN9Nl273IoIicC5yklPpu1LFXo/3R9wYuUkqtMLI7XfZQ4HagN9pVc2kislNKgm+80MjyXsDj9rYL7V72nyZlT0WPNI9C94RyQ2/Ddr5t2yN7NPZAiF22f1eR20VljyLiYdWbdkxpT5fcDJf9fJMyjwHftbf7R53DY2SnRHYf+/8i7FAKmf4XM5OvOWw/0RsBp4i8ChSgey0opQIi8lNgi4gcppR6305/QUTGAq+jB6wOB1You4XaSgdlvwbkicjhSr/pt2W63C4u+3Vb9hFKfz28n+lyu6JsoAZYJ3rSzmkicoxSapNSqtHITpns45RS3wKfxhGRebThrXcYOrrb34GL0KPQxwDfEvU2QwfTfy9q/wygFj0S3redb9y0yO6J12zau2vIRpvhGoANwB3YvUsjO/Nlp/OvLQ1zCPD9qP177UaYA3xupznQdq5ngOFRxx3SocqlSXZPvGbT3l1C9lC0N8gdRLnKGtldQ3Y6/9rSMDmAl4it6nvATfb2IuAn9vZ07NlqSatcmmT3xGs27Z3xsp82sru27HT+tepHr5SqU0r5VCROytHoRQJAT7cfKyKvoP1av2jtfImQLtk98ZrTKbsnXnM7ZH8OyQtla2SnXnZaSeBN6ER/0rxGZLr3KPTI88HAoM56G6VLdk+8ZtPeRraR3bmy0/GXyMxYCz2JYBcwyX7r/QawlFLzlVKbEzhXoqRLdk+85nTK7onXbGT3PNmpJ8G34P7oBppPEma3dgXZPfGaTXsb2UZ29/pLaGasiJQC3wf+qpTytfnAJJAu2T3xmtMpuydes5Hd82SnmoRDIBgMBoOha5HWxcENBoPB0PkYRW8wGAzdHKPoDQaDoZtjFL3BYDB0c4yiNxgMhm6OUfSGHo2IBEVkkYgsE5GvRORKEWnxdyEiw0TknFTV0WDoKEbRG3o69UqpKUqp8ei4J8ehlwFsiWGAUfSGLoPxozf0aESkRimVF7U/AvgMKEGHqP0Xemk5gMuVUgtE5GNgLLAOeBS4E71A9Ex0ZMR7lFL3p+wiDIZWMIre0KNpqujttN3oNUir0bFPGkSvE/uUUmq6iMwEfqmUOsEufzF68ZE/iIgX+BA4Qym1LpXXYjA0R5uWEjQYehihsLRu4G4RmYJeam6vZsrPQgfG+o69X4heu9coekNGYBS9wRCFbboJAjvQtvrtwGT0eFZDc4ehF6x4IyWVNBgSxAzGGgw2ItIHuA+4W2mbZiGwVSlloYNfOe2i1UB+1KFvAJeKiNs+z14ikovBkCGYHr2hp5MtIovQZpoAevD1r3bevcB/ROQM4D30YuAAi4GAiHwFPAL8De2J84W9GtFO4JTUVN9gaB0zGGswGAzdHGO6MRgMhm6OUfQGg8HQzTGK3mAwGLo5RtEbDAZDN8coeoPBYOjmGEVvMBgM3Ryj6A0Gg6Gb8//qohB5qv5+qQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stocks.plot(title=f\"Enbridge Actual Vs. Predicted Prices MSE: 0.001268\")\n",
    "plt.savefig('EnbridgeDay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05356240095039121"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks[\"diff\"] = stocks[\"Real\"] - stocks[\"Predicted\"]\n",
    "stocks[\"diff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "file_path = Path(\"enb_model_1.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
