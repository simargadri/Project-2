{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Change</th>\n",
       "      <th>Low Change</th>\n",
       "      <th>Vix ewm</th>\n",
       "      <th>High/Close</th>\n",
       "      <th>Low/Close</th>\n",
       "      <th>Vix Close</th>\n",
       "      <th>CAD Close</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Spread Change</th>\n",
       "      <th>Volume Diff</th>\n",
       "      <th>Vol change</th>\n",
       "      <th>Return ewm</th>\n",
       "      <th>Vix return</th>\n",
       "      <th>TD return</th>\n",
       "      <th>Tsx return</th>\n",
       "      <th>Cad return</th>\n",
       "      <th>Return</th>\n",
       "      <th>Chaikin</th>\n",
       "      <th>Chaikin Change</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-2.263960e-02</td>\n",
       "      <td>-0.010593</td>\n",
       "      <td>-0.017666</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>-0.004156</td>\n",
       "      <td>19.160000</td>\n",
       "      <td>1.03190</td>\n",
       "      <td>0.372903</td>\n",
       "      <td>-0.546876</td>\n",
       "      <td>814500.0</td>\n",
       "      <td>0.301745</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>-0.009819</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>-0.007354</td>\n",
       "      <td>3.729000e+05</td>\n",
       "      <td>-6.427948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-3.052366e-03</td>\n",
       "      <td>-0.003447</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>-0.008485</td>\n",
       "      <td>19.059999</td>\n",
       "      <td>1.03400</td>\n",
       "      <td>0.385765</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>-1284300.0</td>\n",
       "      <td>-0.365502</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.005219</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.004772</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-4.557000e+05</td>\n",
       "      <td>-2.222043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>9.003467e-04</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>-0.035652</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>18.129999</td>\n",
       "      <td>1.02980</td>\n",
       "      <td>0.327897</td>\n",
       "      <td>-0.150006</td>\n",
       "      <td>-276000.0</td>\n",
       "      <td>-0.123795</td>\n",
       "      <td>-0.002117</td>\n",
       "      <td>-0.048793</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-0.004062</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-3.658500e+05</td>\n",
       "      <td>-0.197169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>-3.993118e-08</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>-0.033211</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>1.03380</td>\n",
       "      <td>0.315038</td>\n",
       "      <td>-0.039217</td>\n",
       "      <td>172300.0</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>-0.001911</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>-9.677500e+04</td>\n",
       "      <td>-0.735479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>-3.419030e-03</td>\n",
       "      <td>-0.006717</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012098</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>1.03920</td>\n",
       "      <td>0.430770</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>243100.0</td>\n",
       "      <td>0.114357</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.010622</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>7.316250e+04</td>\n",
       "      <td>-1.756006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>-1.010593e-03</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>-0.032076</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>22.209999</td>\n",
       "      <td>1.27077</td>\n",
       "      <td>0.530006</td>\n",
       "      <td>-0.480384</td>\n",
       "      <td>-872600.0</td>\n",
       "      <td>-0.348914</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>-0.048007</td>\n",
       "      <td>-0.002540</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>-9.105427e+05</td>\n",
       "      <td>-0.040003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>7.357141e-04</td>\n",
       "      <td>-0.003512</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>1.26981</td>\n",
       "      <td>0.989998</td>\n",
       "      <td>0.867898</td>\n",
       "      <td>2582300.0</td>\n",
       "      <td>1.585887</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>0.046826</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>8.358786e+05</td>\n",
       "      <td>-1.918000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>-3.216602e-03</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.038096</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>24.340000</td>\n",
       "      <td>1.26477</td>\n",
       "      <td>0.959999</td>\n",
       "      <td>-0.030302</td>\n",
       "      <td>565300.0</td>\n",
       "      <td>0.134256</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.046882</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>-0.003969</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>7.005893e+05</td>\n",
       "      <td>-0.161853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>2.209925e-03</td>\n",
       "      <td>-0.004619</td>\n",
       "      <td>-0.017430</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>1.27480</td>\n",
       "      <td>1.089996</td>\n",
       "      <td>2.114289</td>\n",
       "      <td>8780000.0</td>\n",
       "      <td>2.939011</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.045193</td>\n",
       "      <td>-0.005834</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>4.118022e+06</td>\n",
       "      <td>-8.570515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>-7.074574e-03</td>\n",
       "      <td>-0.003712</td>\n",
       "      <td>-0.053429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>21.580000</td>\n",
       "      <td>1.27227</td>\n",
       "      <td>0.720001</td>\n",
       "      <td>-0.339446</td>\n",
       "      <td>-3497400.0</td>\n",
       "      <td>-0.297211</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001985</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>3.103112e+05</td>\n",
       "      <td>-0.924646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2716 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             High Change  Low Change   Vix ewm  High/Close  Low/Close  \\\n",
       "Date                                                                    \n",
       "2010-01-06 -2.263960e-02   -0.010593 -0.017666    0.006325  -0.004156   \n",
       "2010-01-07 -3.052366e-03   -0.003447 -0.009368    0.002347  -0.008485   \n",
       "2010-01-08  9.003467e-04    0.002549 -0.035652    0.005064  -0.004160   \n",
       "2010-01-11 -3.993118e-08    0.000363 -0.033211    0.006885  -0.001993   \n",
       "2010-01-12 -3.419030e-03   -0.006717  0.015520    0.000000  -0.012098   \n",
       "...                  ...         ...       ...         ...        ...   \n",
       "2021-01-13 -1.010593e-03    0.003524 -0.032076    0.001566  -0.003316   \n",
       "2021-01-14  7.357141e-04   -0.003512  0.020525    0.005824  -0.003328   \n",
       "2021-01-15 -3.216602e-03   -0.002968  0.038096    0.000553  -0.008303   \n",
       "2021-01-19  2.209925e-03   -0.004619 -0.017430    0.009647  -0.000464   \n",
       "2021-01-20 -7.074574e-03   -0.003712 -0.053429    0.000000  -0.006662   \n",
       "\n",
       "            Vix Close  CAD Close    Spread  Spread Change  Volume Diff  \\\n",
       "Date                                                                     \n",
       "2010-01-06  19.160000    1.03190  0.372903      -0.546876     814500.0   \n",
       "2010-01-07  19.059999    1.03400  0.385765       0.034490   -1284300.0   \n",
       "2010-01-08  18.129999    1.02980  0.327897      -0.150006    -276000.0   \n",
       "2010-01-11  17.549999    1.03380  0.315038      -0.039217     172300.0   \n",
       "2010-01-12  18.250000    1.03920  0.430770       0.367357     243100.0   \n",
       "...               ...        ...       ...            ...          ...   \n",
       "2021-01-13  22.209999    1.27077  0.530006      -0.480384    -872600.0   \n",
       "2021-01-14  23.250000    1.26981  0.989998       0.867898    2582300.0   \n",
       "2021-01-15  24.340000    1.26477  0.959999      -0.030302     565300.0   \n",
       "2021-01-19  23.240000    1.27480  1.089996       2.114289    8780000.0   \n",
       "2021-01-20  21.580000    1.27227  0.720001      -0.339446   -3497400.0   \n",
       "\n",
       "            Vol change  Return ewm  Vix return  TD return  Tsx return  \\\n",
       "Date                                                                    \n",
       "2010-01-06    0.301745   -0.010025   -0.009819  -0.009845    0.004744   \n",
       "2010-01-07   -0.365502   -0.002739   -0.005219  -0.008700   -0.004772   \n",
       "2010-01-08   -0.123795   -0.002117   -0.048793  -0.001253    0.005577   \n",
       "2010-01-11    0.088201   -0.001911   -0.031991   0.007061   -0.000561   \n",
       "2010-01-12    0.114357    0.001658    0.039886  -0.001247   -0.010622   \n",
       "...                ...         ...         ...        ...         ...   \n",
       "2021-01-13   -0.348914    0.001913   -0.048007  -0.002540   -0.002841   \n",
       "2021-01-14    1.585887   -0.001696    0.046826   0.013269    0.001305   \n",
       "2021-01-15    0.134256    0.000790    0.046882  -0.002381   -0.002734   \n",
       "2021-01-19    2.939011   -0.003195   -0.045193  -0.005834    0.000697   \n",
       "2021-01-20   -0.297211    0.000605   -0.071429  -0.001734    0.003202   \n",
       "\n",
       "            Cad return    Return       Chaikin  Chaikin Change  Pos  \n",
       "Date                                                                 \n",
       "2010-01-06   -0.007311 -0.007354  3.729000e+05       -6.427948    1  \n",
       "2010-01-07    0.002035  0.000904 -4.557000e+05       -2.222043    0  \n",
       "2010-01-08   -0.004062 -0.001806 -3.658500e+05       -0.197169    0  \n",
       "2010-01-11    0.003884 -0.001809 -9.677500e+04       -0.735479    1  \n",
       "2010-01-12    0.005223  0.003443  7.316250e+04       -1.756006    1  \n",
       "...                ...       ...           ...             ...  ...  \n",
       "2021-01-13   -0.004988  0.000922 -9.105427e+05       -0.040003    0  \n",
       "2021-01-14   -0.000755 -0.003500  8.358786e+05       -1.918000    1  \n",
       "2021-01-15   -0.003969  0.002034  7.005893e+05       -0.161853    0  \n",
       "2021-01-19   -0.001308 -0.004617  4.118022e+06       -8.570515    1  \n",
       "2021-01-20   -0.001985  0.002505  3.103112e+05       -0.924646    0  \n",
       "\n",
       "[2716 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rbc_posneg.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['High Change', 'Low Change', 'Vix ewm', 'High/Close', 'Low/Close',\n",
       "       'Vix Close', 'CAD Close', 'Spread', 'Spread Change', 'Volume Diff',\n",
       "       'Vol change', 'Return ewm', 'Vix return', 'TD return', 'Tsx return',\n",
       "       'Cad return', 'Return', 'Chaikin', 'Chaikin Change', 'Pos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vix ewm</th>\n",
       "      <th>High/Close</th>\n",
       "      <th>Low/Close</th>\n",
       "      <th>Vix Close</th>\n",
       "      <th>CAD Close</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Volume Diff</th>\n",
       "      <th>Return ewm</th>\n",
       "      <th>Vix return</th>\n",
       "      <th>TD return</th>\n",
       "      <th>Tsx return</th>\n",
       "      <th>Return</th>\n",
       "      <th>Chaikin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-0.017666</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>-0.004156</td>\n",
       "      <td>19.160000</td>\n",
       "      <td>1.03190</td>\n",
       "      <td>0.372903</td>\n",
       "      <td>814500.0</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>-0.009819</td>\n",
       "      <td>-0.009845</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>-0.007354</td>\n",
       "      <td>3.729000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-0.009368</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>-0.008485</td>\n",
       "      <td>19.059999</td>\n",
       "      <td>1.03400</td>\n",
       "      <td>0.385765</td>\n",
       "      <td>-1284300.0</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.005219</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.004772</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>-4.557000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>-0.035652</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>18.129999</td>\n",
       "      <td>1.02980</td>\n",
       "      <td>0.327897</td>\n",
       "      <td>-276000.0</td>\n",
       "      <td>-0.002117</td>\n",
       "      <td>-0.048793</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-0.001806</td>\n",
       "      <td>-3.658500e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>-0.033211</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>17.549999</td>\n",
       "      <td>1.03380</td>\n",
       "      <td>0.315038</td>\n",
       "      <td>172300.0</td>\n",
       "      <td>-0.001911</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>-9.677500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012098</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>1.03920</td>\n",
       "      <td>0.430770</td>\n",
       "      <td>243100.0</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.010622</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>7.316250e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>-0.032076</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>-0.003316</td>\n",
       "      <td>22.209999</td>\n",
       "      <td>1.27077</td>\n",
       "      <td>0.530006</td>\n",
       "      <td>-872600.0</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>-0.048007</td>\n",
       "      <td>-0.002540</td>\n",
       "      <td>-0.002841</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>-9.105427e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>0.020525</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>1.26981</td>\n",
       "      <td>0.989998</td>\n",
       "      <td>2582300.0</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>0.046826</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>8.358786e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>0.038096</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>24.340000</td>\n",
       "      <td>1.26477</td>\n",
       "      <td>0.959999</td>\n",
       "      <td>565300.0</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.046882</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>7.005893e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>-0.017430</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>23.240000</td>\n",
       "      <td>1.27480</td>\n",
       "      <td>1.089996</td>\n",
       "      <td>8780000.0</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.045193</td>\n",
       "      <td>-0.005834</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-0.004617</td>\n",
       "      <td>4.118022e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>-0.053429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>21.580000</td>\n",
       "      <td>1.27227</td>\n",
       "      <td>0.720001</td>\n",
       "      <td>-3497400.0</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>3.103112e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2716 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Vix ewm  High/Close  Low/Close  Vix Close  CAD Close    Spread  \\\n",
       "Date                                                                          \n",
       "2010-01-06 -0.017666    0.006325  -0.004156  19.160000    1.03190  0.372903   \n",
       "2010-01-07 -0.009368    0.002347  -0.008485  19.059999    1.03400  0.385765   \n",
       "2010-01-08 -0.035652    0.005064  -0.004160  18.129999    1.02980  0.327897   \n",
       "2010-01-11 -0.033211    0.006885  -0.001993  17.549999    1.03380  0.315038   \n",
       "2010-01-12  0.015520    0.000000  -0.012098  18.250000    1.03920  0.430770   \n",
       "...              ...         ...        ...        ...        ...       ...   \n",
       "2021-01-13 -0.032076    0.001566  -0.003316  22.209999    1.27077  0.530006   \n",
       "2021-01-14  0.020525    0.005824  -0.003328  23.250000    1.26981  0.989998   \n",
       "2021-01-15  0.038096    0.000553  -0.008303  24.340000    1.26477  0.959999   \n",
       "2021-01-19 -0.017430    0.009647  -0.000464  23.240000    1.27480  1.089996   \n",
       "2021-01-20 -0.053429    0.000000  -0.006662  21.580000    1.27227  0.720001   \n",
       "\n",
       "            Volume Diff  Return ewm  Vix return  TD return  Tsx return  \\\n",
       "Date                                                                     \n",
       "2010-01-06     814500.0   -0.010025   -0.009819  -0.009845    0.004744   \n",
       "2010-01-07   -1284300.0   -0.002739   -0.005219  -0.008700   -0.004772   \n",
       "2010-01-08    -276000.0   -0.002117   -0.048793  -0.001253    0.005577   \n",
       "2010-01-11     172300.0   -0.001911   -0.031991   0.007061   -0.000561   \n",
       "2010-01-12     243100.0    0.001658    0.039886  -0.001247   -0.010622   \n",
       "...                 ...         ...         ...        ...         ...   \n",
       "2021-01-13    -872600.0    0.001913   -0.048007  -0.002540   -0.002841   \n",
       "2021-01-14    2582300.0   -0.001696    0.046826   0.013269    0.001305   \n",
       "2021-01-15     565300.0    0.000790    0.046882  -0.002381   -0.002734   \n",
       "2021-01-19    8780000.0   -0.003195   -0.045193  -0.005834    0.000697   \n",
       "2021-01-20   -3497400.0    0.000605   -0.071429  -0.001734    0.003202   \n",
       "\n",
       "              Return       Chaikin  \n",
       "Date                                \n",
       "2010-01-06 -0.007354  3.729000e+05  \n",
       "2010-01-07  0.000904 -4.557000e+05  \n",
       "2010-01-08 -0.001806 -3.658500e+05  \n",
       "2010-01-11 -0.001809 -9.677500e+04  \n",
       "2010-01-12  0.003443  7.316250e+04  \n",
       "...              ...           ...  \n",
       "2021-01-13  0.000922 -9.105427e+05  \n",
       "2021-01-14 -0.003500  8.358786e+05  \n",
       "2021-01-15  0.002034  7.005893e+05  \n",
       "2021-01-19 -0.004617  4.118022e+06  \n",
       "2021-01-20  0.002505  3.103112e+05  \n",
       "\n",
       "[2716 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = df[['Vix ewm', 'High/Close', 'Low/Close',\n",
    "       'Vix Close', 'CAD Close', 'Spread', 'Volume Diff',\n",
    "       'Return ewm', 'Vix return', 'TD return', 'Tsx return',\n",
    "       'Return', 'Chaikin']]\n",
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pos\n",
       "Date           \n",
       "2010-01-06    1\n",
       "2010-01-07    0\n",
       "2010-01-08    0\n",
       "2010-01-11    1\n",
       "2010-01-12    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[[\"Pos\"]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_input, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaler = MinMaxScaler()\n",
    "x_test_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "x_train_scaler.fit(x_train)\n",
    "x_test_scaler.fit(x_test)\n",
    "\n",
    "\n",
    "x_train = x_train_scaler.transform(x_train)\n",
    "x_test = x_test_scaler.transform(x_test)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "\n",
    "encoded_y_train = enc.transform(y_train).toarray()\n",
    "encoded_y_test = enc.transform(y_test).toarray()\n",
    "encoded_y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 44\n",
    "features = x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 64\n",
    "drop = 0.2\n",
    "\n",
    "nn = Sequential()\n",
    "\n",
    "nn.add(Dense(units=units, input_dim=features, activation=\"relu\"))\n",
    "\n",
    "nn.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,026\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def mean_pred(encoded_y_train, encoded_y_test):\n",
    "    return K.mean(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_loss = logs[\"val_accuracy\"]\n",
    "        if val_loss > self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1901 samples, validate on 815 samples\n",
      "Epoch 1/500\n",
      "1901/1901 [==============================] - 1s 488us/sample - loss: 0.6892 - accuracy: 0.5539 - val_loss: 0.6917 - val_accuracy: 0.5337\n",
      "Epoch 2/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6865 - accuracy: 0.5576 - val_loss: 0.7004 - val_accuracy: 0.5301\n",
      "Epoch 3/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6868 - accuracy: 0.5587 - val_loss: 0.6976 - val_accuracy: 0.5276\n",
      "Epoch 4/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6860 - accuracy: 0.5539 - val_loss: 0.7004 - val_accuracy: 0.5288\n",
      "Epoch 5/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6854 - accuracy: 0.5539 - val_loss: 0.6940 - val_accuracy: 0.5301\n",
      "Epoch 6/500\n",
      "1901/1901 [==============================] - 0s 84us/sample - loss: 0.6862 - accuracy: 0.5634 - val_loss: 0.6997 - val_accuracy: 0.5276\n",
      "Epoch 7/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6856 - accuracy: 0.5560 - val_loss: 0.6975 - val_accuracy: 0.5264\n",
      "Epoch 8/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6844 - accuracy: 0.5697 - val_loss: 0.6943 - val_accuracy: 0.5288\n",
      "Epoch 9/500\n",
      "1901/1901 [==============================] - 0s 105us/sample - loss: 0.6842 - accuracy: 0.5671 - val_loss: 0.6949 - val_accuracy: 0.5288\n",
      "Epoch 10/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6840 - accuracy: 0.5655 - val_loss: 0.6973 - val_accuracy: 0.5301\n",
      "Epoch 11/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6836 - accuracy: 0.5634 - val_loss: 0.6961 - val_accuracy: 0.5301\n",
      "Epoch 12/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6851 - accuracy: 0.5518 - val_loss: 0.7020 - val_accuracy: 0.5313\n",
      "Epoch 13/500\n",
      "1901/1901 [==============================] - 0s 98us/sample - loss: 0.6877 - accuracy: 0.5434 - val_loss: 0.6997 - val_accuracy: 0.5301\n",
      "Epoch 14/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6862 - accuracy: 0.5550 - val_loss: 0.6984 - val_accuracy: 0.5301\n",
      "Epoch 15/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6827 - accuracy: 0.5587 - val_loss: 0.6985 - val_accuracy: 0.5301\n",
      "Epoch 16/500\n",
      "1901/1901 [==============================] - 0s 98us/sample - loss: 0.6826 - accuracy: 0.5639 - val_loss: 0.7061 - val_accuracy: 0.5313\n",
      "Epoch 17/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6837 - accuracy: 0.5650 - val_loss: 0.7079 - val_accuracy: 0.5301\n",
      "Epoch 18/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6828 - accuracy: 0.5592 - val_loss: 0.6906 - val_accuracy: 0.5387\n",
      "Epoch 19/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6843 - accuracy: 0.5555 - val_loss: 0.7049 - val_accuracy: 0.5301\n",
      "Epoch 20/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6809 - accuracy: 0.5581 - val_loss: 0.6919 - val_accuracy: 0.5288\n",
      "Epoch 21/500\n",
      "1901/1901 [==============================] - 0s 84us/sample - loss: 0.6836 - accuracy: 0.5471 - val_loss: 0.7036 - val_accuracy: 0.5301\n",
      "Epoch 22/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6821 - accuracy: 0.5655 - val_loss: 0.7063 - val_accuracy: 0.5313\n",
      "Epoch 23/500\n",
      "1901/1901 [==============================] - 0s 98us/sample - loss: 0.6836 - accuracy: 0.5613 - val_loss: 0.6980 - val_accuracy: 0.5325\n",
      "Epoch 24/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6816 - accuracy: 0.5623 - val_loss: 0.6957 - val_accuracy: 0.5325\n",
      "Epoch 25/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6815 - accuracy: 0.5655 - val_loss: 0.7073 - val_accuracy: 0.5288\n",
      "Epoch 26/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6806 - accuracy: 0.5686 - val_loss: 0.6937 - val_accuracy: 0.5337\n",
      "Epoch 27/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6827 - accuracy: 0.5718 - val_loss: 0.6923 - val_accuracy: 0.5350\n",
      "Epoch 28/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6829 - accuracy: 0.5587 - val_loss: 0.7239 - val_accuracy: 0.5301\n",
      "Epoch 29/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6828 - accuracy: 0.5618 - val_loss: 0.7003 - val_accuracy: 0.5325\n",
      "Epoch 30/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6818 - accuracy: 0.5613 - val_loss: 0.7028 - val_accuracy: 0.5313\n",
      "Epoch 31/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6800 - accuracy: 0.5676 - val_loss: 0.7068 - val_accuracy: 0.5301\n",
      "Epoch 32/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6810 - accuracy: 0.5650 - val_loss: 0.7050 - val_accuracy: 0.5313\n",
      "Epoch 33/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6805 - accuracy: 0.5618 - val_loss: 0.7041 - val_accuracy: 0.5325\n",
      "Epoch 34/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6804 - accuracy: 0.5618 - val_loss: 0.7009 - val_accuracy: 0.5313\n",
      "Epoch 35/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6799 - accuracy: 0.5713 - val_loss: 0.7095 - val_accuracy: 0.5301\n",
      "Epoch 36/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6800 - accuracy: 0.5650 - val_loss: 0.7135 - val_accuracy: 0.5301\n",
      "Epoch 37/500\n",
      "1901/1901 [==============================] - 0s 90us/sample - loss: 0.6817 - accuracy: 0.5555 - val_loss: 0.7063 - val_accuracy: 0.5301\n",
      "Epoch 38/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6805 - accuracy: 0.5629 - val_loss: 0.7050 - val_accuracy: 0.5288\n",
      "Epoch 39/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6800 - accuracy: 0.5571 - val_loss: 0.7061 - val_accuracy: 0.5313\n",
      "Epoch 40/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6795 - accuracy: 0.5708 - val_loss: 0.7006 - val_accuracy: 0.5313\n",
      "Epoch 41/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6798 - accuracy: 0.5692 - val_loss: 0.6981 - val_accuracy: 0.5362\n",
      "Epoch 42/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6793 - accuracy: 0.5671 - val_loss: 0.7052 - val_accuracy: 0.5325\n",
      "Epoch 43/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6807 - accuracy: 0.5623 - val_loss: 0.7107 - val_accuracy: 0.5313\n",
      "Epoch 44/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6790 - accuracy: 0.5723 - val_loss: 0.7069 - val_accuracy: 0.5325\n",
      "Epoch 45/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6797 - accuracy: 0.5686 - val_loss: 0.7072 - val_accuracy: 0.5337\n",
      "Epoch 46/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6788 - accuracy: 0.5671 - val_loss: 0.7081 - val_accuracy: 0.5325\n",
      "Epoch 47/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6797 - accuracy: 0.5681 - val_loss: 0.7181 - val_accuracy: 0.5288\n",
      "Epoch 48/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6798 - accuracy: 0.5650 - val_loss: 0.7059 - val_accuracy: 0.5301\n",
      "Epoch 49/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6788 - accuracy: 0.5723 - val_loss: 0.7027 - val_accuracy: 0.5313\n",
      "Epoch 50/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6790 - accuracy: 0.5660 - val_loss: 0.7001 - val_accuracy: 0.5387\n",
      "Epoch 51/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6789 - accuracy: 0.5655 - val_loss: 0.7070 - val_accuracy: 0.5313\n",
      "Epoch 52/500\n",
      "1901/1901 [==============================] - 0s 100us/sample - loss: 0.6794 - accuracy: 0.5702 - val_loss: 0.6976 - val_accuracy: 0.5411\n",
      "Epoch 53/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6782 - accuracy: 0.5723 - val_loss: 0.7149 - val_accuracy: 0.5276\n",
      "Epoch 54/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6789 - accuracy: 0.5713 - val_loss: 0.7023 - val_accuracy: 0.5337\n",
      "Epoch 55/500\n",
      "1901/1901 [==============================] - 0s 90us/sample - loss: 0.6797 - accuracy: 0.5681 - val_loss: 0.7068 - val_accuracy: 0.5301\n",
      "Epoch 56/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6784 - accuracy: 0.5702 - val_loss: 0.7105 - val_accuracy: 0.5325\n",
      "Epoch 57/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6784 - accuracy: 0.5718 - val_loss: 0.7080 - val_accuracy: 0.5301\n",
      "Epoch 58/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6780 - accuracy: 0.5686 - val_loss: 0.7033 - val_accuracy: 0.5337\n",
      "Epoch 59/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6786 - accuracy: 0.5697 - val_loss: 0.7105 - val_accuracy: 0.5313\n",
      "Epoch 60/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6784 - accuracy: 0.5729 - val_loss: 0.6999 - val_accuracy: 0.5374\n",
      "Epoch 61/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6773 - accuracy: 0.5739 - val_loss: 0.7021 - val_accuracy: 0.5374\n",
      "Epoch 62/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6791 - accuracy: 0.5639 - val_loss: 0.7001 - val_accuracy: 0.5374\n",
      "Epoch 63/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6772 - accuracy: 0.5660 - val_loss: 0.7102 - val_accuracy: 0.5301\n",
      "Epoch 64/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6782 - accuracy: 0.5713 - val_loss: 0.7053 - val_accuracy: 0.5325\n",
      "Epoch 65/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6765 - accuracy: 0.5660 - val_loss: 0.6948 - val_accuracy: 0.5436\n",
      "Epoch 66/500\n",
      "1901/1901 [==============================] - 0s 98us/sample - loss: 0.6777 - accuracy: 0.5692 - val_loss: 0.7159 - val_accuracy: 0.5288\n",
      "Epoch 67/500\n",
      "1901/1901 [==============================] - 0s 128us/sample - loss: 0.6773 - accuracy: 0.5750 - val_loss: 0.6987 - val_accuracy: 0.5436\n",
      "Epoch 68/500\n",
      "1901/1901 [==============================] - 0s 108us/sample - loss: 0.6782 - accuracy: 0.5729 - val_loss: 0.7030 - val_accuracy: 0.5350\n",
      "Epoch 69/500\n",
      "1901/1901 [==============================] - 0s 106us/sample - loss: 0.6774 - accuracy: 0.5723 - val_loss: 0.7042 - val_accuracy: 0.5350\n",
      "Epoch 70/500\n",
      "1901/1901 [==============================] - 0s 107us/sample - loss: 0.6765 - accuracy: 0.5729 - val_loss: 0.7139 - val_accuracy: 0.5313\n",
      "Epoch 71/500\n",
      "1901/1901 [==============================] - 0s 97us/sample - loss: 0.6778 - accuracy: 0.5697 - val_loss: 0.7105 - val_accuracy: 0.5301\n",
      "Epoch 72/500\n",
      "1901/1901 [==============================] - 0s 94us/sample - loss: 0.6796 - accuracy: 0.5592 - val_loss: 0.7166 - val_accuracy: 0.5313\n",
      "Epoch 73/500\n",
      "1901/1901 [==============================] - 0s 105us/sample - loss: 0.6776 - accuracy: 0.5708 - val_loss: 0.7097 - val_accuracy: 0.5288\n",
      "Epoch 74/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6773 - accuracy: 0.5765 - val_loss: 0.7023 - val_accuracy: 0.5337\n",
      "Epoch 75/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6764 - accuracy: 0.5718 - val_loss: 0.7158 - val_accuracy: 0.5276\n",
      "Epoch 76/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6791 - accuracy: 0.5734 - val_loss: 0.7195 - val_accuracy: 0.5301\n",
      "Epoch 77/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6796 - accuracy: 0.5639 - val_loss: 0.7027 - val_accuracy: 0.5350\n",
      "Epoch 78/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6773 - accuracy: 0.5708 - val_loss: 0.7055 - val_accuracy: 0.5350\n",
      "Epoch 79/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.7017 - val_accuracy: 0.5399\n",
      "Epoch 80/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6776 - accuracy: 0.5702 - val_loss: 0.7075 - val_accuracy: 0.5337\n",
      "Epoch 81/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6764 - accuracy: 0.5786 - val_loss: 0.7166 - val_accuracy: 0.5301\n",
      "Epoch 82/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6775 - accuracy: 0.5755 - val_loss: 0.7246 - val_accuracy: 0.5301\n",
      "Epoch 83/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6772 - accuracy: 0.5734 - val_loss: 0.6995 - val_accuracy: 0.5399\n",
      "Epoch 84/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6765 - accuracy: 0.5739 - val_loss: 0.6984 - val_accuracy: 0.5423\n",
      "Epoch 85/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6762 - accuracy: 0.5744 - val_loss: 0.7039 - val_accuracy: 0.5362\n",
      "Epoch 86/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6760 - accuracy: 0.5797 - val_loss: 0.7020 - val_accuracy: 0.5399\n",
      "Epoch 87/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6780 - accuracy: 0.5729 - val_loss: 0.7012 - val_accuracy: 0.5399\n",
      "Epoch 88/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6769 - accuracy: 0.5692 - val_loss: 0.7042 - val_accuracy: 0.5350\n",
      "Epoch 89/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6758 - accuracy: 0.5739 - val_loss: 0.7159 - val_accuracy: 0.5288\n",
      "Epoch 90/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6754 - accuracy: 0.5797 - val_loss: 0.7155 - val_accuracy: 0.5276\n",
      "Epoch 91/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6771 - accuracy: 0.5771 - val_loss: 0.7019 - val_accuracy: 0.5362\n",
      "Epoch 92/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6744 - accuracy: 0.5702 - val_loss: 0.7172 - val_accuracy: 0.5288\n",
      "Epoch 93/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6771 - accuracy: 0.5650 - val_loss: 0.7058 - val_accuracy: 0.5350\n",
      "Epoch 94/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6756 - accuracy: 0.5760 - val_loss: 0.7056 - val_accuracy: 0.5337\n",
      "Epoch 95/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6759 - accuracy: 0.5755 - val_loss: 0.6960 - val_accuracy: 0.5399\n",
      "Epoch 96/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6750 - accuracy: 0.5702 - val_loss: 0.7067 - val_accuracy: 0.5362\n",
      "Epoch 97/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6747 - accuracy: 0.5765 - val_loss: 0.6965 - val_accuracy: 0.5448\n",
      "Epoch 98/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6756 - accuracy: 0.5692 - val_loss: 0.7056 - val_accuracy: 0.5337\n",
      "Epoch 99/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6750 - accuracy: 0.5797 - val_loss: 0.7127 - val_accuracy: 0.5301\n",
      "Epoch 100/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6760 - accuracy: 0.5786 - val_loss: 0.7077 - val_accuracy: 0.5350\n",
      "Epoch 101/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6771 - accuracy: 0.5655 - val_loss: 0.7167 - val_accuracy: 0.5276\n",
      "Epoch 102/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6754 - accuracy: 0.5771 - val_loss: 0.7007 - val_accuracy: 0.5436\n",
      "Epoch 103/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6751 - accuracy: 0.5739 - val_loss: 0.7123 - val_accuracy: 0.5313\n",
      "Epoch 104/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6743 - accuracy: 0.5844 - val_loss: 0.6977 - val_accuracy: 0.5387\n",
      "Epoch 105/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6746 - accuracy: 0.5807 - val_loss: 0.7045 - val_accuracy: 0.5362\n",
      "Epoch 106/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6748 - accuracy: 0.5792 - val_loss: 0.7027 - val_accuracy: 0.5374\n",
      "Epoch 107/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6734 - accuracy: 0.5829 - val_loss: 0.7183 - val_accuracy: 0.5288\n",
      "Epoch 108/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6757 - accuracy: 0.5781 - val_loss: 0.7019 - val_accuracy: 0.5387\n",
      "Epoch 109/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6746 - accuracy: 0.5776 - val_loss: 0.7025 - val_accuracy: 0.5387\n",
      "Epoch 110/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6759 - accuracy: 0.5807 - val_loss: 0.7143 - val_accuracy: 0.5313\n",
      "Epoch 111/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6739 - accuracy: 0.5871 - val_loss: 0.6985 - val_accuracy: 0.5387\n",
      "Epoch 112/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6762 - accuracy: 0.5718 - val_loss: 0.7025 - val_accuracy: 0.5411\n",
      "Epoch 113/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6748 - accuracy: 0.5734 - val_loss: 0.7011 - val_accuracy: 0.5423\n",
      "Epoch 114/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6740 - accuracy: 0.5755 - val_loss: 0.7229 - val_accuracy: 0.5288\n",
      "Epoch 115/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6749 - accuracy: 0.5834 - val_loss: 0.7007 - val_accuracy: 0.5436\n",
      "Epoch 116/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6740 - accuracy: 0.5813 - val_loss: 0.7040 - val_accuracy: 0.5350\n",
      "Epoch 117/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6744 - accuracy: 0.5771 - val_loss: 0.7026 - val_accuracy: 0.5362\n",
      "Epoch 118/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6733 - accuracy: 0.5781 - val_loss: 0.6985 - val_accuracy: 0.5399\n",
      "Epoch 119/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6743 - accuracy: 0.5729 - val_loss: 0.7071 - val_accuracy: 0.5362\n",
      "Epoch 120/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6745 - accuracy: 0.5844 - val_loss: 0.7007 - val_accuracy: 0.5313\n",
      "Epoch 121/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6734 - accuracy: 0.5823 - val_loss: 0.7125 - val_accuracy: 0.5350\n",
      "Epoch 122/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6736 - accuracy: 0.5823 - val_loss: 0.6963 - val_accuracy: 0.5509\n",
      "Epoch 123/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6733 - accuracy: 0.5839 - val_loss: 0.7126 - val_accuracy: 0.5325\n",
      "Epoch 124/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6736 - accuracy: 0.5781 - val_loss: 0.7049 - val_accuracy: 0.5325\n",
      "Epoch 125/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6735 - accuracy: 0.5744 - val_loss: 0.7044 - val_accuracy: 0.5337\n",
      "Epoch 126/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6732 - accuracy: 0.5776 - val_loss: 0.7083 - val_accuracy: 0.5337\n",
      "Epoch 127/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6735 - accuracy: 0.5834 - val_loss: 0.7015 - val_accuracy: 0.5325\n",
      "Epoch 128/500\n",
      "1901/1901 [==============================] - 0s 104us/sample - loss: 0.6733 - accuracy: 0.5802 - val_loss: 0.7075 - val_accuracy: 0.5337\n",
      "Epoch 129/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6731 - accuracy: 0.5813 - val_loss: 0.7085 - val_accuracy: 0.5337\n",
      "Epoch 130/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6727 - accuracy: 0.5708 - val_loss: 0.7139 - val_accuracy: 0.5325\n",
      "Epoch 131/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6736 - accuracy: 0.5829 - val_loss: 0.7164 - val_accuracy: 0.5325\n",
      "Epoch 132/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6745 - accuracy: 0.5776 - val_loss: 0.7099 - val_accuracy: 0.5350\n",
      "Epoch 133/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6734 - accuracy: 0.5744 - val_loss: 0.7103 - val_accuracy: 0.5325\n",
      "Epoch 134/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6736 - accuracy: 0.5781 - val_loss: 0.7043 - val_accuracy: 0.5337\n",
      "Epoch 135/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6723 - accuracy: 0.5776 - val_loss: 0.7217 - val_accuracy: 0.5325\n",
      "Epoch 136/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6726 - accuracy: 0.5844 - val_loss: 0.7105 - val_accuracy: 0.5337\n",
      "Epoch 137/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6726 - accuracy: 0.5802 - val_loss: 0.7043 - val_accuracy: 0.5325\n",
      "Epoch 138/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6739 - accuracy: 0.5797 - val_loss: 0.7080 - val_accuracy: 0.5313\n",
      "Epoch 139/500\n",
      "1901/1901 [==============================] - 0s 94us/sample - loss: 0.6730 - accuracy: 0.5797 - val_loss: 0.7073 - val_accuracy: 0.5350\n",
      "Epoch 140/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6725 - accuracy: 0.5829 - val_loss: 0.7083 - val_accuracy: 0.5350\n",
      "Epoch 141/500\n",
      "1901/1901 [==============================] - 0s 79us/sample - loss: 0.6718 - accuracy: 0.5818 - val_loss: 0.7074 - val_accuracy: 0.5313\n",
      "Epoch 142/500\n",
      "1901/1901 [==============================] - 0s 111us/sample - loss: 0.6731 - accuracy: 0.5818 - val_loss: 0.7047 - val_accuracy: 0.5325\n",
      "Epoch 143/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6723 - accuracy: 0.5792 - val_loss: 0.7074 - val_accuracy: 0.5313\n",
      "Epoch 144/500\n",
      "1901/1901 [==============================] - 0s 62us/sample - loss: 0.6722 - accuracy: 0.5797 - val_loss: 0.7089 - val_accuracy: 0.5337\n",
      "Epoch 145/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6725 - accuracy: 0.5823 - val_loss: 0.7017 - val_accuracy: 0.5374\n",
      "Epoch 146/500\n",
      "1901/1901 [==============================] - 0s 81us/sample - loss: 0.6717 - accuracy: 0.5886 - val_loss: 0.7012 - val_accuracy: 0.5362\n",
      "Epoch 147/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6722 - accuracy: 0.5823 - val_loss: 0.7046 - val_accuracy: 0.5325\n",
      "Epoch 148/500\n",
      "1901/1901 [==============================] - 0s 81us/sample - loss: 0.6723 - accuracy: 0.5823 - val_loss: 0.7077 - val_accuracy: 0.5301\n",
      "Epoch 149/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6714 - accuracy: 0.5844 - val_loss: 0.7102 - val_accuracy: 0.5325\n",
      "Epoch 150/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6724 - accuracy: 0.5818 - val_loss: 0.7095 - val_accuracy: 0.5301\n",
      "Epoch 151/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6740 - accuracy: 0.5897 - val_loss: 0.7121 - val_accuracy: 0.5325\n",
      "Epoch 152/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6734 - accuracy: 0.5755 - val_loss: 0.7060 - val_accuracy: 0.5325\n",
      "Epoch 153/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6714 - accuracy: 0.5829 - val_loss: 0.7039 - val_accuracy: 0.5350\n",
      "Epoch 154/500\n",
      "1901/1901 [==============================] - 0s 63us/sample - loss: 0.6715 - accuracy: 0.5839 - val_loss: 0.7036 - val_accuracy: 0.5350\n",
      "Epoch 155/500\n",
      "1901/1901 [==============================] - 0s 64us/sample - loss: 0.6717 - accuracy: 0.5802 - val_loss: 0.7096 - val_accuracy: 0.5313\n",
      "Epoch 156/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6707 - accuracy: 0.5839 - val_loss: 0.7028 - val_accuracy: 0.5436\n",
      "Epoch 157/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6705 - accuracy: 0.5881 - val_loss: 0.7065 - val_accuracy: 0.5337\n",
      "Epoch 158/500\n",
      "1901/1901 [==============================] - 0s 104us/sample - loss: 0.6732 - accuracy: 0.5797 - val_loss: 0.6985 - val_accuracy: 0.5472\n",
      "Epoch 159/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6712 - accuracy: 0.5818 - val_loss: 0.6999 - val_accuracy: 0.5448\n",
      "Epoch 160/500\n",
      "1901/1901 [==============================] - 0s 97us/sample - loss: 0.6717 - accuracy: 0.5813 - val_loss: 0.7040 - val_accuracy: 0.5423\n",
      "Epoch 161/500\n",
      "1901/1901 [==============================] - 0s 81us/sample - loss: 0.6716 - accuracy: 0.5818 - val_loss: 0.7050 - val_accuracy: 0.5325\n",
      "Epoch 162/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6712 - accuracy: 0.5829 - val_loss: 0.6998 - val_accuracy: 0.5534\n",
      "Epoch 163/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6705 - accuracy: 0.5855 - val_loss: 0.7046 - val_accuracy: 0.5337\n",
      "Epoch 164/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6705 - accuracy: 0.5865 - val_loss: 0.7001 - val_accuracy: 0.5485\n",
      "Epoch 165/500\n",
      "1901/1901 [==============================] - 0s 77us/sample - loss: 0.6703 - accuracy: 0.5829 - val_loss: 0.7092 - val_accuracy: 0.5337\n",
      "Epoch 166/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6704 - accuracy: 0.5844 - val_loss: 0.7117 - val_accuracy: 0.5337\n",
      "Epoch 167/500\n",
      "1901/1901 [==============================] - 0s 65us/sample - loss: 0.6704 - accuracy: 0.5818 - val_loss: 0.7184 - val_accuracy: 0.5337\n",
      "Epoch 168/500\n",
      "1901/1901 [==============================] - 0s 99us/sample - loss: 0.6700 - accuracy: 0.5844 - val_loss: 0.6991 - val_accuracy: 0.5423\n",
      "Epoch 169/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6709 - accuracy: 0.5844 - val_loss: 0.7038 - val_accuracy: 0.5374\n",
      "Epoch 170/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6697 - accuracy: 0.5855 - val_loss: 0.7112 - val_accuracy: 0.5350\n",
      "Epoch 171/500\n",
      "1901/1901 [==============================] - 0s 115us/sample - loss: 0.6706 - accuracy: 0.5834 - val_loss: 0.7119 - val_accuracy: 0.5337\n",
      "Epoch 172/500\n",
      "1901/1901 [==============================] - 0s 90us/sample - loss: 0.6698 - accuracy: 0.5844 - val_loss: 0.7048 - val_accuracy: 0.5325\n",
      "Epoch 173/500\n",
      "1901/1901 [==============================] - 0s 96us/sample - loss: 0.6698 - accuracy: 0.5876 - val_loss: 0.7009 - val_accuracy: 0.5436\n",
      "Epoch 174/500\n",
      "1901/1901 [==============================] - 0s 107us/sample - loss: 0.6705 - accuracy: 0.5865 - val_loss: 0.6987 - val_accuracy: 0.5546\n",
      "Epoch 175/500\n",
      "1901/1901 [==============================] - 0s 97us/sample - loss: 0.6705 - accuracy: 0.5844 - val_loss: 0.7044 - val_accuracy: 0.5399\n",
      "Epoch 176/500\n",
      "1901/1901 [==============================] - 0s 105us/sample - loss: 0.6702 - accuracy: 0.5813 - val_loss: 0.7070 - val_accuracy: 0.5411\n",
      "Epoch 177/500\n",
      "1901/1901 [==============================] - 0s 103us/sample - loss: 0.6706 - accuracy: 0.5844 - val_loss: 0.7059 - val_accuracy: 0.5350\n",
      "Epoch 178/500\n",
      "1901/1901 [==============================] - 0s 115us/sample - loss: 0.6696 - accuracy: 0.5850 - val_loss: 0.7047 - val_accuracy: 0.5387\n",
      "Epoch 179/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6697 - accuracy: 0.5860 - val_loss: 0.7107 - val_accuracy: 0.5337\n",
      "Epoch 180/500\n",
      "1901/1901 [==============================] - 0s 96us/sample - loss: 0.6703 - accuracy: 0.5813 - val_loss: 0.7086 - val_accuracy: 0.5374\n",
      "Epoch 181/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6686 - accuracy: 0.5823 - val_loss: 0.7018 - val_accuracy: 0.5436\n",
      "Epoch 182/500\n",
      "1901/1901 [==============================] - 0s 64us/sample - loss: 0.6700 - accuracy: 0.5818 - val_loss: 0.7027 - val_accuracy: 0.5472\n",
      "Epoch 183/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6708 - accuracy: 0.5865 - val_loss: 0.6994 - val_accuracy: 0.5448\n",
      "Epoch 184/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6701 - accuracy: 0.5823 - val_loss: 0.6999 - val_accuracy: 0.5472\n",
      "Epoch 185/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6708 - accuracy: 0.5823 - val_loss: 0.6997 - val_accuracy: 0.5509\n",
      "Epoch 186/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6689 - accuracy: 0.5881 - val_loss: 0.7106 - val_accuracy: 0.5362\n",
      "Epoch 187/500\n",
      "1901/1901 [==============================] - 0s 79us/sample - loss: 0.6686 - accuracy: 0.5886 - val_loss: 0.7029 - val_accuracy: 0.5399\n",
      "Epoch 188/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6708 - accuracy: 0.5829 - val_loss: 0.7058 - val_accuracy: 0.5411\n",
      "Epoch 189/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6691 - accuracy: 0.5844 - val_loss: 0.7095 - val_accuracy: 0.5399\n",
      "Epoch 190/500\n",
      "1901/1901 [==============================] - 0s 65us/sample - loss: 0.6692 - accuracy: 0.5902 - val_loss: 0.7065 - val_accuracy: 0.5387\n",
      "Epoch 191/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6693 - accuracy: 0.5823 - val_loss: 0.7062 - val_accuracy: 0.5387\n",
      "Epoch 192/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6693 - accuracy: 0.5860 - val_loss: 0.7128 - val_accuracy: 0.5387\n",
      "Epoch 193/500\n",
      "1901/1901 [==============================] - 0s 77us/sample - loss: 0.6692 - accuracy: 0.5876 - val_loss: 0.7119 - val_accuracy: 0.5362\n",
      "Epoch 194/500\n",
      "1901/1901 [==============================] - 0s 77us/sample - loss: 0.6688 - accuracy: 0.5881 - val_loss: 0.7049 - val_accuracy: 0.5423\n",
      "Epoch 195/500\n",
      "1901/1901 [==============================] - 0s 64us/sample - loss: 0.6688 - accuracy: 0.5813 - val_loss: 0.7074 - val_accuracy: 0.5362\n",
      "Epoch 196/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6689 - accuracy: 0.5813 - val_loss: 0.7026 - val_accuracy: 0.5472\n",
      "Epoch 197/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6689 - accuracy: 0.5876 - val_loss: 0.7068 - val_accuracy: 0.5387\n",
      "Epoch 198/500\n",
      "1901/1901 [==============================] - 0s 63us/sample - loss: 0.6696 - accuracy: 0.5813 - val_loss: 0.7059 - val_accuracy: 0.5399\n",
      "Epoch 199/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6682 - accuracy: 0.5860 - val_loss: 0.7064 - val_accuracy: 0.5485\n",
      "Epoch 200/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6682 - accuracy: 0.5865 - val_loss: 0.7029 - val_accuracy: 0.5399\n",
      "Epoch 201/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6687 - accuracy: 0.5855 - val_loss: 0.7037 - val_accuracy: 0.5436\n",
      "Epoch 202/500\n",
      "1901/1901 [==============================] - 0s 81us/sample - loss: 0.6684 - accuracy: 0.5829 - val_loss: 0.7019 - val_accuracy: 0.5485\n",
      "Epoch 203/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6682 - accuracy: 0.5897 - val_loss: 0.7093 - val_accuracy: 0.5374\n",
      "Epoch 204/500\n",
      "1901/1901 [==============================] - 0s 65us/sample - loss: 0.6677 - accuracy: 0.5813 - val_loss: 0.7011 - val_accuracy: 0.5497\n",
      "Epoch 205/500\n",
      "1901/1901 [==============================] - 0s 77us/sample - loss: 0.6682 - accuracy: 0.5860 - val_loss: 0.7124 - val_accuracy: 0.5350\n",
      "Epoch 206/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6694 - accuracy: 0.5850 - val_loss: 0.7062 - val_accuracy: 0.5423\n",
      "Epoch 207/500\n",
      "1901/1901 [==============================] - 0s 65us/sample - loss: 0.6685 - accuracy: 0.5839 - val_loss: 0.7077 - val_accuracy: 0.5485\n",
      "Epoch 208/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6686 - accuracy: 0.5823 - val_loss: 0.7066 - val_accuracy: 0.5411\n",
      "Epoch 209/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6685 - accuracy: 0.5860 - val_loss: 0.7117 - val_accuracy: 0.5387\n",
      "Epoch 210/500\n",
      "1901/1901 [==============================] - 0s 67us/sample - loss: 0.6677 - accuracy: 0.5892 - val_loss: 0.7127 - val_accuracy: 0.5374\n",
      "Epoch 211/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6679 - accuracy: 0.5855 - val_loss: 0.7040 - val_accuracy: 0.5485\n",
      "Epoch 212/500\n",
      "1901/1901 [==============================] - 0s 66us/sample - loss: 0.6678 - accuracy: 0.5860 - val_loss: 0.7119 - val_accuracy: 0.5411\n",
      "Epoch 213/500\n",
      "1901/1901 [==============================] - 0s 63us/sample - loss: 0.6662 - accuracy: 0.5813 - val_loss: 0.7256 - val_accuracy: 0.5301\n",
      "Epoch 214/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6682 - accuracy: 0.5892 - val_loss: 0.7140 - val_accuracy: 0.5411\n",
      "Epoch 215/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6678 - accuracy: 0.5886 - val_loss: 0.7102 - val_accuracy: 0.5399\n",
      "Epoch 216/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6662 - accuracy: 0.5902 - val_loss: 0.7104 - val_accuracy: 0.5399\n",
      "Epoch 217/500\n",
      "1901/1901 [==============================] - 0s 95us/sample - loss: 0.6668 - accuracy: 0.5897 - val_loss: 0.7040 - val_accuracy: 0.5448\n",
      "Epoch 218/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6680 - accuracy: 0.5860 - val_loss: 0.7064 - val_accuracy: 0.5460\n",
      "Epoch 219/500\n",
      "1901/1901 [==============================] - 0s 63us/sample - loss: 0.6668 - accuracy: 0.5897 - val_loss: 0.7021 - val_accuracy: 0.5436\n",
      "Epoch 220/500\n",
      "1901/1901 [==============================] - 0s 65us/sample - loss: 0.6691 - accuracy: 0.5839 - val_loss: 0.7035 - val_accuracy: 0.5497\n",
      "Epoch 221/500\n",
      "1901/1901 [==============================] - 0s 68us/sample - loss: 0.6682 - accuracy: 0.5834 - val_loss: 0.7094 - val_accuracy: 0.5460\n",
      "Epoch 222/500\n",
      "1901/1901 [==============================] - 0s 64us/sample - loss: 0.6668 - accuracy: 0.5829 - val_loss: 0.7098 - val_accuracy: 0.5399\n",
      "Epoch 223/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6687 - accuracy: 0.5876 - val_loss: 0.7223 - val_accuracy: 0.5313\n",
      "Epoch 224/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6677 - accuracy: 0.5802 - val_loss: 0.7090 - val_accuracy: 0.5399\n",
      "Epoch 225/500\n",
      "1901/1901 [==============================] - 0s 94us/sample - loss: 0.6668 - accuracy: 0.5923 - val_loss: 0.7115 - val_accuracy: 0.5448\n",
      "Epoch 226/500\n",
      "1901/1901 [==============================] - 0s 64us/sample - loss: 0.6661 - accuracy: 0.5881 - val_loss: 0.7153 - val_accuracy: 0.5387\n",
      "Epoch 227/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6673 - accuracy: 0.5907 - val_loss: 0.7053 - val_accuracy: 0.5497\n",
      "Epoch 228/500\n",
      "1901/1901 [==============================] - 0s 110us/sample - loss: 0.6665 - accuracy: 0.5886 - val_loss: 0.7131 - val_accuracy: 0.5423\n",
      "Epoch 229/500\n",
      "1901/1901 [==============================] - 0s 103us/sample - loss: 0.6674 - accuracy: 0.5886 - val_loss: 0.7122 - val_accuracy: 0.5423\n",
      "Epoch 230/500\n",
      "1901/1901 [==============================] - 0s 105us/sample - loss: 0.6660 - accuracy: 0.5918 - val_loss: 0.7109 - val_accuracy: 0.5399\n",
      "Epoch 231/500\n",
      "1901/1901 [==============================] - 0s 113us/sample - loss: 0.6665 - accuracy: 0.5939 - val_loss: 0.7085 - val_accuracy: 0.5485\n",
      "Epoch 232/500\n",
      "1901/1901 [==============================] - 0s 108us/sample - loss: 0.6663 - accuracy: 0.5865 - val_loss: 0.7152 - val_accuracy: 0.5387\n",
      "Epoch 233/500\n",
      "1901/1901 [==============================] - 0s 97us/sample - loss: 0.6676 - accuracy: 0.5997 - val_loss: 0.7129 - val_accuracy: 0.5387\n",
      "Epoch 234/500\n",
      "1901/1901 [==============================] - 0s 113us/sample - loss: 0.6659 - accuracy: 0.5907 - val_loss: 0.7189 - val_accuracy: 0.5362\n",
      "Epoch 235/500\n",
      "1901/1901 [==============================] - 0s 90us/sample - loss: 0.6667 - accuracy: 0.5928 - val_loss: 0.7081 - val_accuracy: 0.5460\n",
      "Epoch 236/500\n",
      "1901/1901 [==============================] - 0s 95us/sample - loss: 0.6665 - accuracy: 0.5892 - val_loss: 0.7075 - val_accuracy: 0.5399\n",
      "Epoch 237/500\n",
      "1901/1901 [==============================] - 0s 99us/sample - loss: 0.6691 - accuracy: 0.5786 - val_loss: 0.7227 - val_accuracy: 0.5337\n",
      "Epoch 238/500\n",
      "1901/1901 [==============================] - 0s 108us/sample - loss: 0.6660 - accuracy: 0.5971 - val_loss: 0.7303 - val_accuracy: 0.5325\n",
      "Epoch 239/500\n",
      "1901/1901 [==============================] - 0s 102us/sample - loss: 0.6660 - accuracy: 0.5892 - val_loss: 0.7119 - val_accuracy: 0.5472\n",
      "Epoch 240/500\n",
      "1901/1901 [==============================] - 0s 95us/sample - loss: 0.6686 - accuracy: 0.5855 - val_loss: 0.7096 - val_accuracy: 0.5460\n",
      "Epoch 241/500\n",
      "1901/1901 [==============================] - 0s 94us/sample - loss: 0.6661 - accuracy: 0.5913 - val_loss: 0.7087 - val_accuracy: 0.5497\n",
      "Epoch 242/500\n",
      "1901/1901 [==============================] - 0s 104us/sample - loss: 0.6657 - accuracy: 0.5850 - val_loss: 0.7178 - val_accuracy: 0.5387\n",
      "Epoch 243/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6647 - accuracy: 0.5907 - val_loss: 0.7085 - val_accuracy: 0.5534\n",
      "Epoch 244/500\n",
      "1901/1901 [==============================] - 0s 98us/sample - loss: 0.6655 - accuracy: 0.5944 - val_loss: 0.7170 - val_accuracy: 0.5387\n",
      "Epoch 245/500\n",
      "1901/1901 [==============================] - 0s 108us/sample - loss: 0.6661 - accuracy: 0.5918 - val_loss: 0.7086 - val_accuracy: 0.5436\n",
      "Epoch 246/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6652 - accuracy: 0.5939 - val_loss: 0.7181 - val_accuracy: 0.5423\n",
      "Epoch 247/500\n",
      "1901/1901 [==============================] - 0s 94us/sample - loss: 0.6657 - accuracy: 0.5902 - val_loss: 0.7119 - val_accuracy: 0.5460\n",
      "Epoch 248/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6646 - accuracy: 0.5928 - val_loss: 0.7147 - val_accuracy: 0.5399\n",
      "Epoch 249/500\n",
      "1901/1901 [==============================] - 0s 102us/sample - loss: 0.6650 - accuracy: 0.5944 - val_loss: 0.7112 - val_accuracy: 0.5521\n",
      "Epoch 250/500\n",
      "1901/1901 [==============================] - 0s 106us/sample - loss: 0.6647 - accuracy: 0.5997 - val_loss: 0.7129 - val_accuracy: 0.5448\n",
      "Epoch 251/500\n",
      "1901/1901 [==============================] - 0s 102us/sample - loss: 0.6671 - accuracy: 0.5918 - val_loss: 0.7217 - val_accuracy: 0.5362\n",
      "Epoch 252/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6650 - accuracy: 0.5886 - val_loss: 0.7089 - val_accuracy: 0.5521\n",
      "Epoch 253/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6645 - accuracy: 0.5960 - val_loss: 0.7166 - val_accuracy: 0.5485\n",
      "Epoch 254/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6660 - accuracy: 0.5865 - val_loss: 0.7201 - val_accuracy: 0.5411\n",
      "Epoch 255/500\n",
      "1901/1901 [==============================] - 0s 107us/sample - loss: 0.6658 - accuracy: 0.5892 - val_loss: 0.7112 - val_accuracy: 0.5485\n",
      "Epoch 256/500\n",
      "1901/1901 [==============================] - 0s 102us/sample - loss: 0.6652 - accuracy: 0.5918 - val_loss: 0.7117 - val_accuracy: 0.5509\n",
      "Epoch 257/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6644 - accuracy: 0.5886 - val_loss: 0.7109 - val_accuracy: 0.5521\n",
      "Epoch 258/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6646 - accuracy: 0.5944 - val_loss: 0.7168 - val_accuracy: 0.5472\n",
      "Epoch 259/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6654 - accuracy: 0.5881 - val_loss: 0.7137 - val_accuracy: 0.5485\n",
      "Epoch 260/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6652 - accuracy: 0.5986 - val_loss: 0.7250 - val_accuracy: 0.5387\n",
      "Epoch 261/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6648 - accuracy: 0.5944 - val_loss: 0.7100 - val_accuracy: 0.5411\n",
      "Epoch 262/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6647 - accuracy: 0.5865 - val_loss: 0.7118 - val_accuracy: 0.5423\n",
      "Epoch 263/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6650 - accuracy: 0.5934 - val_loss: 0.7155 - val_accuracy: 0.5472\n",
      "Epoch 264/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6630 - accuracy: 0.5892 - val_loss: 0.7180 - val_accuracy: 0.5472\n",
      "Epoch 265/500\n",
      "1901/1901 [==============================] - 0s 95us/sample - loss: 0.6638 - accuracy: 0.6007 - val_loss: 0.7135 - val_accuracy: 0.5509\n",
      "Epoch 266/500\n",
      "1901/1901 [==============================] - 0s 81us/sample - loss: 0.6651 - accuracy: 0.5976 - val_loss: 0.7215 - val_accuracy: 0.5399\n",
      "Epoch 267/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6649 - accuracy: 0.5960 - val_loss: 0.7142 - val_accuracy: 0.5460\n",
      "Epoch 268/500\n",
      "1901/1901 [==============================] - 0s 111us/sample - loss: 0.6643 - accuracy: 0.5886 - val_loss: 0.7254 - val_accuracy: 0.5374\n",
      "Epoch 269/500\n",
      "1901/1901 [==============================] - 0s 111us/sample - loss: 0.6643 - accuracy: 0.5934 - val_loss: 0.7261 - val_accuracy: 0.5350\n",
      "Epoch 270/500\n",
      "1901/1901 [==============================] - 0s 108us/sample - loss: 0.6630 - accuracy: 0.5997 - val_loss: 0.7174 - val_accuracy: 0.5534\n",
      "Epoch 271/500\n",
      "1901/1901 [==============================] - 0s 109us/sample - loss: 0.6635 - accuracy: 0.5992 - val_loss: 0.7138 - val_accuracy: 0.5399\n",
      "Epoch 272/500\n",
      "1901/1901 [==============================] - 0s 117us/sample - loss: 0.6643 - accuracy: 0.5976 - val_loss: 0.7270 - val_accuracy: 0.5350\n",
      "Epoch 273/500\n",
      "1901/1901 [==============================] - 0s 102us/sample - loss: 0.6636 - accuracy: 0.5928 - val_loss: 0.7139 - val_accuracy: 0.5546\n",
      "Epoch 274/500\n",
      "1901/1901 [==============================] - 0s 95us/sample - loss: 0.6636 - accuracy: 0.5918 - val_loss: 0.7150 - val_accuracy: 0.5509\n",
      "Epoch 275/500\n",
      "1901/1901 [==============================] - 0s 93us/sample - loss: 0.6637 - accuracy: 0.5892 - val_loss: 0.7144 - val_accuracy: 0.5472\n",
      "Epoch 276/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6649 - accuracy: 0.5865 - val_loss: 0.7175 - val_accuracy: 0.5497\n",
      "Epoch 277/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6637 - accuracy: 0.5976 - val_loss: 0.7080 - val_accuracy: 0.5521\n",
      "Epoch 278/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6651 - accuracy: 0.5986 - val_loss: 0.7126 - val_accuracy: 0.5521\n",
      "Epoch 279/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6634 - accuracy: 0.5928 - val_loss: 0.7259 - val_accuracy: 0.5411\n",
      "Epoch 280/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6640 - accuracy: 0.5944 - val_loss: 0.7251 - val_accuracy: 0.5387\n",
      "Epoch 281/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6619 - accuracy: 0.5960 - val_loss: 0.7140 - val_accuracy: 0.5411\n",
      "Epoch 282/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6630 - accuracy: 0.5986 - val_loss: 0.7257 - val_accuracy: 0.5423\n",
      "Epoch 283/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6622 - accuracy: 0.5939 - val_loss: 0.7217 - val_accuracy: 0.5460\n",
      "Epoch 284/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6625 - accuracy: 0.5971 - val_loss: 0.7358 - val_accuracy: 0.5362\n",
      "Epoch 285/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6620 - accuracy: 0.5934 - val_loss: 0.7140 - val_accuracy: 0.5472\n",
      "Epoch 286/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6644 - accuracy: 0.5902 - val_loss: 0.7224 - val_accuracy: 0.5436\n",
      "Epoch 287/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6629 - accuracy: 0.5923 - val_loss: 0.7216 - val_accuracy: 0.5460\n",
      "Epoch 288/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6626 - accuracy: 0.5992 - val_loss: 0.7173 - val_accuracy: 0.5497\n",
      "Epoch 289/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6635 - accuracy: 0.5913 - val_loss: 0.7176 - val_accuracy: 0.5436\n",
      "Epoch 290/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6637 - accuracy: 0.5960 - val_loss: 0.7230 - val_accuracy: 0.5521\n",
      "Epoch 291/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6628 - accuracy: 0.5939 - val_loss: 0.7211 - val_accuracy: 0.5460\n",
      "Epoch 292/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6633 - accuracy: 0.5897 - val_loss: 0.7254 - val_accuracy: 0.5460\n",
      "Epoch 293/500\n",
      "1901/1901 [==============================] - 0s 69us/sample - loss: 0.6635 - accuracy: 0.5844 - val_loss: 0.7242 - val_accuracy: 0.5460\n",
      "Epoch 294/500\n",
      "1901/1901 [==============================] - 0s 71us/sample - loss: 0.6625 - accuracy: 0.5939 - val_loss: 0.7173 - val_accuracy: 0.5423\n",
      "Epoch 295/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6621 - accuracy: 0.5918 - val_loss: 0.7370 - val_accuracy: 0.5325\n",
      "Epoch 296/500\n",
      "1901/1901 [==============================] - 0s 85us/sample - loss: 0.6628 - accuracy: 0.5907 - val_loss: 0.7145 - val_accuracy: 0.5485\n",
      "Epoch 297/500\n",
      "1901/1901 [==============================] - 0s 70us/sample - loss: 0.6637 - accuracy: 0.5813 - val_loss: 0.7400 - val_accuracy: 0.5301\n",
      "Epoch 298/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6614 - accuracy: 0.5860 - val_loss: 0.7175 - val_accuracy: 0.5411\n",
      "Epoch 299/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6621 - accuracy: 0.5971 - val_loss: 0.7142 - val_accuracy: 0.5521\n",
      "Epoch 300/500\n",
      "1901/1901 [==============================] - 0s 91us/sample - loss: 0.6627 - accuracy: 0.6013 - val_loss: 0.7245 - val_accuracy: 0.5485\n",
      "Epoch 301/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6615 - accuracy: 0.5997 - val_loss: 0.7318 - val_accuracy: 0.5411\n",
      "Epoch 302/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6616 - accuracy: 0.5976 - val_loss: 0.7196 - val_accuracy: 0.5485\n",
      "Epoch 303/500\n",
      "1901/1901 [==============================] - 0s 87us/sample - loss: 0.6624 - accuracy: 0.5939 - val_loss: 0.7316 - val_accuracy: 0.5411\n",
      "Epoch 304/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6618 - accuracy: 0.5939 - val_loss: 0.7269 - val_accuracy: 0.5472\n",
      "Epoch 305/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6618 - accuracy: 0.5939 - val_loss: 0.7375 - val_accuracy: 0.5325\n",
      "Epoch 306/500\n",
      "1901/1901 [==============================] - 0s 75us/sample - loss: 0.6625 - accuracy: 0.5923 - val_loss: 0.7395 - val_accuracy: 0.5301\n",
      "Epoch 307/500\n",
      "1901/1901 [==============================] - 0s 76us/sample - loss: 0.6618 - accuracy: 0.5939 - val_loss: 0.7412 - val_accuracy: 0.5337\n",
      "Epoch 308/500\n",
      "1901/1901 [==============================] - 0s 114us/sample - loss: 0.6616 - accuracy: 0.5913 - val_loss: 0.7314 - val_accuracy: 0.5448\n",
      "Epoch 309/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6631 - accuracy: 0.5965 - val_loss: 0.7313 - val_accuracy: 0.5411\n",
      "Epoch 310/500\n",
      "1901/1901 [==============================] - 0s 97us/sample - loss: 0.6609 - accuracy: 0.5944 - val_loss: 0.7208 - val_accuracy: 0.5387\n",
      "Epoch 311/500\n",
      "1901/1901 [==============================] - 0s 88us/sample - loss: 0.6608 - accuracy: 0.5976 - val_loss: 0.7179 - val_accuracy: 0.5509\n",
      "Epoch 312/500\n",
      "1901/1901 [==============================] - 0s 82us/sample - loss: 0.6621 - accuracy: 0.5934 - val_loss: 0.7336 - val_accuracy: 0.5460\n",
      "Epoch 313/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6610 - accuracy: 0.5944 - val_loss: 0.7196 - val_accuracy: 0.5460\n",
      "Epoch 314/500\n",
      "1901/1901 [==============================] - 0s 89us/sample - loss: 0.6605 - accuracy: 0.5944 - val_loss: 0.7217 - val_accuracy: 0.5399\n",
      "Epoch 315/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6614 - accuracy: 0.5981 - val_loss: 0.7284 - val_accuracy: 0.5448\n",
      "Epoch 316/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6603 - accuracy: 0.5939 - val_loss: 0.7202 - val_accuracy: 0.5374\n",
      "Epoch 317/500\n",
      "1901/1901 [==============================] - 0s 101us/sample - loss: 0.6620 - accuracy: 0.5881 - val_loss: 0.7261 - val_accuracy: 0.5472\n",
      "Epoch 318/500\n",
      "1901/1901 [==============================] - 0s 86us/sample - loss: 0.6617 - accuracy: 0.6007 - val_loss: 0.7179 - val_accuracy: 0.5460\n",
      "Epoch 319/500\n",
      "1901/1901 [==============================] - 0s 72us/sample - loss: 0.6614 - accuracy: 0.5986 - val_loss: 0.7240 - val_accuracy: 0.5436\n",
      "Epoch 320/500\n",
      "1901/1901 [==============================] - 0s 83us/sample - loss: 0.6605 - accuracy: 0.5886 - val_loss: 0.7179 - val_accuracy: 0.5436\n",
      "Epoch 321/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6617 - accuracy: 0.5939 - val_loss: 0.7238 - val_accuracy: 0.5485\n",
      "Epoch 322/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6622 - accuracy: 0.6023 - val_loss: 0.7206 - val_accuracy: 0.5472\n",
      "Epoch 323/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6603 - accuracy: 0.5986 - val_loss: 0.7195 - val_accuracy: 0.5423\n",
      "Epoch 324/500\n",
      "1901/1901 [==============================] - 0s 92us/sample - loss: 0.6626 - accuracy: 0.5907 - val_loss: 0.7292 - val_accuracy: 0.5497\n",
      "Epoch 325/500\n",
      "1901/1901 [==============================] - 0s 80us/sample - loss: 0.6617 - accuracy: 0.6055 - val_loss: 0.7370 - val_accuracy: 0.5472\n",
      "Epoch 326/500\n",
      "1901/1901 [==============================] - 0s 78us/sample - loss: 0.6617 - accuracy: 0.5923 - val_loss: 0.7404 - val_accuracy: 0.5350\n",
      "Epoch 327/500\n",
      "1901/1901 [==============================] - 0s 73us/sample - loss: 0.6616 - accuracy: 0.5881 - val_loss: 0.7189 - val_accuracy: 0.5448\n",
      "Epoch 328/500\n",
      "1901/1901 [==============================] - 0s 74us/sample - loss: 0.6593 - accuracy: 0.5981 - val_loss: 0.7223 - val_accuracy: 0.5399\n",
      "Epoch 329/500\n",
      "1901/1901 [==============================] - 0s 77us/sample - loss: 0.6612 - accuracy: 0.5997 - val_loss: 0.7293 - val_accuracy: 0.5571\n"
     ]
    }
   ],
   "source": [
    "earlystop = ThresholdCallback(threshold=0.557)\n",
    "\n",
    "model = nn.fit(x_train, encoded_y_train, validation_data=(x_test, encoded_y_test), \n",
    "               epochs=500, callbacks=[earlystop], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/1 - 0s - loss: 0.7377 - accuracy: 0.5571\n",
      "Normal Neural Network - Loss: 0.7293200490664851, Accuracy: 0.5570552349090576\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(x_test, encoded_y_test, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0       1          1\n",
       "1       1          1\n",
       "2       1          1\n",
       "3       1          1\n",
       "4       0          1\n",
       "5       1          1\n",
       "6       0          1\n",
       "7       1          1\n",
       "8       0          1\n",
       "9       0          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = nn.predict(x_test)\n",
    "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test.Pos.values,\n",
    "    \"Predicted\": predicted\n",
    "})\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history[\"val_accuracy\"])\n",
    "plt.legend([\"train\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55705523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(model.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19       382\n",
      "           1       0.55      0.95      0.70       433\n",
      "\n",
      "    accuracy                           0.56       815\n",
      "   macro avg       0.61      0.53      0.44       815\n",
      "weighted avg       0.61      0.56      0.46       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(results.Actual, results.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = nn.to_json()\n",
    "file_path = Path(\"rbc_model_posneg.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "file_path = \"rbc_weights_posneg.h5\"\n",
    "nn.save_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
