{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Oil Close</th>\n",
       "      <th>Enb Close</th>\n",
       "      <th>Target Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>14.707242</td>\n",
       "      <td>81.769997</td>\n",
       "      <td>14.897686</td>\n",
       "      <td>14.559792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>14.467640</td>\n",
       "      <td>83.180000</td>\n",
       "      <td>14.559792</td>\n",
       "      <td>14.513723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>14.295634</td>\n",
       "      <td>82.660004</td>\n",
       "      <td>14.513723</td>\n",
       "      <td>14.538293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>14.464572</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>14.538293</td>\n",
       "      <td>14.436925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>14.375491</td>\n",
       "      <td>82.519997</td>\n",
       "      <td>14.436925</td>\n",
       "      <td>14.427713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>47.740002</td>\n",
       "      <td>41.549999</td>\n",
       "      <td>41.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.119999</td>\n",
       "      <td>47.020000</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.189999</td>\n",
       "      <td>48.119999</td>\n",
       "      <td>41.279999</td>\n",
       "      <td>41.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.790001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>40.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>48.400002</td>\n",
       "      <td>40.820000</td>\n",
       "      <td>40.709999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Low  Oil Close  Enb Close  Target Close\n",
       "Date                                                     \n",
       "2010-01-05  14.707242  81.769997  14.897686     14.559792\n",
       "2010-01-06  14.467640  83.180000  14.559792     14.513723\n",
       "2010-01-07  14.295634  82.660004  14.513723     14.538293\n",
       "2010-01-08  14.464572  82.750000  14.538293     14.436925\n",
       "2010-01-11  14.375491  82.519997  14.436925     14.427713\n",
       "...               ...        ...        ...           ...\n",
       "2020-12-21  40.639999  47.740002  41.549999     41.230000\n",
       "2020-12-22  41.119999  47.020000  41.230000     41.279999\n",
       "2020-12-23  41.189999  48.119999  41.279999     41.250000\n",
       "2020-12-29  40.790001  48.000000  40.799999     40.820000\n",
       "2020-12-30  40.639999  48.400002  40.820000     40.709999\n",
       "\n",
       "[2689 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('eng.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=[\"SU Close\", \"Volume\", \"Open\", \"Gas Close\", \"TSX Close\", \"High\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df.iloc[:, :-1]\n",
    "df_output = df[[\"Enb Close\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_input, df_output, test_size=0.3, random_state=42, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1882, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(807, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Oil Close</th>\n",
       "      <th>Enb Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-11</th>\n",
       "      <td>40.012272</td>\n",
       "      <td>48.070000</td>\n",
       "      <td>40.280537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-12</th>\n",
       "      <td>40.044792</td>\n",
       "      <td>48.230000</td>\n",
       "      <td>40.573196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>40.532544</td>\n",
       "      <td>49.299999</td>\n",
       "      <td>40.540672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>40.500030</td>\n",
       "      <td>49.889999</td>\n",
       "      <td>40.719521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>40.475641</td>\n",
       "      <td>49.889999</td>\n",
       "      <td>40.768295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>47.740002</td>\n",
       "      <td>41.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.119999</td>\n",
       "      <td>47.020000</td>\n",
       "      <td>41.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.189999</td>\n",
       "      <td>48.119999</td>\n",
       "      <td>41.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.790001</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>40.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.639999</td>\n",
       "      <td>48.400002</td>\n",
       "      <td>40.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Low  Oil Close  Enb Close\n",
       "Date                                       \n",
       "2017-09-11  40.012272  48.070000  40.280537\n",
       "2017-09-12  40.044792  48.230000  40.573196\n",
       "2017-09-13  40.532544  49.299999  40.540672\n",
       "2017-09-14  40.500030  49.889999  40.719521\n",
       "2017-09-15  40.475641  49.889999  40.768295\n",
       "...               ...        ...        ...\n",
       "2020-12-21  40.639999  47.740002  41.549999\n",
       "2020-12-22  41.119999  47.020000  41.230000\n",
       "2020-12-23  41.189999  48.119999  41.279999\n",
       "2020-12-29  40.790001  48.000000  40.799999\n",
       "2020-12-30  40.639999  48.400002  40.820000\n",
       "\n",
       "[807 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaler = MinMaxScaler()\n",
    "x_test_scaler = MinMaxScaler()\n",
    "\n",
    "y_train_scaler = MinMaxScaler()\n",
    "y_test_scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaler.fit(x_train)\n",
    "x_test_scaler.fit(x_test)\n",
    "\n",
    "y_train_scaler.fit(y_train)\n",
    "y_test_scaler.fit(y_test)\n",
    "\n",
    "x_train = x_train_scaler.transform(x_train)\n",
    "x_test = x_test_scaler.transform(x_test)\n",
    "\n",
    "y_train = y_train_scaler.transform(y_train)\n",
    "y_test = y_test_scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 1\n",
    "batch = 44\n",
    "features = 3\n",
    "\n",
    "train_generator = TimeseriesGenerator(x_train, y_train, length=length, sampling_rate=1, batch_size=batch)\n",
    "test_generator = TimeseriesGenerator(x_test, y_test, length=length, sampling_rate=1, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "units = 64\n",
    "drop = 0.2\n",
    "\n",
    "#1st layer\n",
    "model.add(LSTM(units=units, return_sequences=True, input_shape=(length, features)))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "#2nd layer\n",
    "model.add(LSTM(units=units, return_sequences=True))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "#3rd layer\n",
    "model.add(LSTM(units=units))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1, 64)             17408     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1, 64)             33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 83,521\n",
      "Trainable params: 83,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(ThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_loss = logs[\"val_loss\"]\n",
    "        if val_loss < self.threshold:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0018 - val_loss: 0.0041\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 3s 79ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 3s 75ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0019 - val_loss: 0.0045\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0017 - val_loss: 0.0042\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 6s 137ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0020 - val_loss: 0.0052\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0020 - val_loss: 0.0060\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 5s 111ms/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0019 - val_loss: 0.0046\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 6s 128ms/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 7s 155ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 5s 111ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 6s 128ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 4s 100ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 6s 149ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 5s 126ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.0015 - val_loss: 0.0030\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 5s 114ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 6s 140ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 4s 91ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0017 - val_loss: 0.0040\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 5s 111ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 6s 135ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 4s 94ms/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 4s 100ms/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 115/1000\n",
      "43/43 [==============================] - 4s 99ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 6s 137ms/step - loss: 0.0015 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 4s 105ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 5s 107ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 6s 130ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 6s 136ms/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 5s 125ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 150/1000\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 151/1000\n",
      "43/43 [==============================] - 6s 132ms/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 152/1000\n",
      "43/43 [==============================] - 6s 139ms/step - loss: 0.0037 - val_loss: 0.0122\n",
      "Epoch 153/1000\n",
      "43/43 [==============================] - 7s 159ms/step - loss: 0.0031 - val_loss: 0.0057\n",
      "Epoch 154/1000\n",
      "43/43 [==============================] - 7s 153ms/step - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 155/1000\n",
      "43/43 [==============================] - 6s 145ms/step - loss: 0.0035 - val_loss: 0.0072\n",
      "Epoch 156/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 157/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 158/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 159/1000\n",
      "43/43 [==============================] - 5s 118ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 160/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 161/1000\n",
      "43/43 [==============================] - 5s 117ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 162/1000\n",
      "43/43 [==============================] - 7s 154ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 163/1000\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 164/1000\n",
      "43/43 [==============================] - 7s 166ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 165/1000\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 166/1000\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 167/1000\n",
      "43/43 [==============================] - 6s 151ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 168/1000\n",
      "43/43 [==============================] - 6s 134ms/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 169/1000\n",
      "43/43 [==============================] - 6s 143ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 170/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 171/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 172/1000\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 173/1000\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 174/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 175/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 176/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 177/1000\n",
      "43/43 [==============================] - 6s 135ms/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 178/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 179/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 180/1000\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 181/1000\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 182/1000\n",
      "43/43 [==============================] - 6s 144ms/step - loss: 0.0019 - val_loss: 0.00170s - loss\n",
      "Epoch 183/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 184/1000\n",
      "43/43 [==============================] - 5s 115ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 185/1000\n",
      "43/43 [==============================] - 5s 121ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 186/1000\n",
      "43/43 [==============================] - 6s 128ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 187/1000\n",
      "43/43 [==============================] - 5s 127ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 188/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 189/1000\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 190/1000\n",
      "43/43 [==============================] - 7s 168ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 191/1000\n",
      "43/43 [==============================] - 6s 150ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 192/1000\n",
      "43/43 [==============================] - 6s 148ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 193/1000\n",
      "43/43 [==============================] - 9s 210ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 194/1000\n",
      "43/43 [==============================] - 7s 160ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 195/1000\n",
      "43/43 [==============================] - 5s 123ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 196/1000\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 197/1000\n",
      "43/43 [==============================] - 7s 162ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 198/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 199/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 200/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 201/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 202/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 203/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 204/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 205/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 206/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 207/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 208/1000\n",
      "43/43 [==============================] - 4s 82ms/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 209/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 210/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 211/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 212/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 213/1000\n",
      "43/43 [==============================] - 4s 100ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 214/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 215/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 216/1000\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 217/1000\n",
      "43/43 [==============================] - 6s 141ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 218/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 219/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 220/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 221/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 222/1000\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 223/1000\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 224/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 225/1000\n",
      "43/43 [==============================] - 5s 109ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 226/1000\n",
      "43/43 [==============================] - 6s 129ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 227/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 228/1000\n",
      "43/43 [==============================] - 3s 81ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 229/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 230/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 231/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 232/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 233/1000\n",
      "43/43 [==============================] - 3s 78ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 234/1000\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 235/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 236/1000\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 237/1000\n",
      "43/43 [==============================] - 5s 112ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 238/1000\n",
      "43/43 [==============================] - 4s 101ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 239/1000\n",
      "43/43 [==============================] - 4s 104ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 240/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 241/1000\n",
      "43/43 [==============================] - 5s 106ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 242/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 243/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 244/1000\n",
      "43/43 [==============================] - 5s 108ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 245/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 246/1000\n",
      "43/43 [==============================] - 4s 87ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 247/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 248/1000\n",
      "43/43 [==============================] - 4s 95ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 249/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 250/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 251/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 252/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 253/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 254/1000\n",
      "43/43 [==============================] - 5s 113ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 255/1000\n",
      "43/43 [==============================] - 6s 149ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 256/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 257/1000\n",
      "43/43 [==============================] - 3s 77ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 258/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 259/1000\n",
      "43/43 [==============================] - 3s 68ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 260/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 261/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 262/1000\n",
      "43/43 [==============================] - 5s 110ms/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 263/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 264/1000\n",
      "43/43 [==============================] - 4s 92ms/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 265/1000\n",
      "43/43 [==============================] - 4s 90ms/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 266/1000\n",
      "43/43 [==============================] - 6s 133ms/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 267/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 268/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0026 - val_loss: 0.0060\n",
      "Epoch 269/1000\n",
      "43/43 [==============================] - 6s 128ms/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 270/1000\n",
      "43/43 [==============================] - 4s 83ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 271/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 272/1000\n",
      "43/43 [==============================] - 4s 85ms/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 273/1000\n",
      "43/43 [==============================] - 4s 86ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 274/1000\n",
      "43/43 [==============================] - 4s 97ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 275/1000\n",
      "43/43 [==============================] - 3s 69ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 276/1000\n",
      "43/43 [==============================] - 3s 73ms/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 277/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 278/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 279/1000\n",
      "43/43 [==============================] - 4s 98ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 280/1000\n",
      "43/43 [==============================] - 4s 102ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 281/1000\n",
      "43/43 [==============================] - 5s 120ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 282/1000\n",
      "43/43 [==============================] - 5s 116ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 283/1000\n",
      "43/43 [==============================] - 3s 80ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 284/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 285/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 286/1000\n",
      "43/43 [==============================] - 3s 70ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 287/1000\n",
      "43/43 [==============================] - 3s 71ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 288/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 289/1000\n",
      "43/43 [==============================] - 3s 63ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 290/1000\n",
      "43/43 [==============================] - 3s 66ms/step - loss: 0.0018 - val_loss: 0.0042\n",
      "Epoch 291/1000\n",
      "43/43 [==============================] - 3s 62ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 292/1000\n",
      "43/43 [==============================] - 3s 72ms/step - loss: 0.0022 - val_loss: 0.0055\n",
      "Epoch 293/1000\n",
      "43/43 [==============================] - 3s 65ms/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 294/1000\n",
      "43/43 [==============================] - 3s 64ms/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 295/1000\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 296/1000\n",
      "43/43 [==============================] - 5s 105ms/step - loss: 0.0023 - val_loss: 0.0052\n",
      "Epoch 297/1000\n",
      "43/43 [==============================] - 6s 142ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 298/1000\n",
      "43/43 [==============================] - 5s 122ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 299/1000\n",
      "43/43 [==============================] - 5s 119ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 300/1000\n",
      "43/43 [==============================] - 4s 93ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 301/1000\n",
      "43/43 [==============================] - 4s 89ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 302/1000\n",
      "43/43 [==============================] - 5s 124ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 303/1000\n",
      "43/43 [==============================] - 4s 103ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 304/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 305/1000\n",
      "43/43 [==============================] - 4s 96ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 306/1000\n",
      "43/43 [==============================] - 4s 84ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, mode='min')\n",
    "\n",
    "earlystop = ThresholdCallback(threshold=0.0013)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "fit = model.fit_generator(train_generator, epochs = 1000, validation_data=test_generator,\n",
    "                         shuffle=False, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001268391924799959"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = y_test_scaler.inverse_transform(predictions)\n",
    "real_prices = y_test_scaler.inverse_transform(y_test[1:].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-12</th>\n",
       "      <td>40.573196</td>\n",
       "      <td>40.314247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-13</th>\n",
       "      <td>40.540672</td>\n",
       "      <td>40.489613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-14</th>\n",
       "      <td>40.719521</td>\n",
       "      <td>40.694805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-15</th>\n",
       "      <td>40.768295</td>\n",
       "      <td>40.779522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-18</th>\n",
       "      <td>40.922752</td>\n",
       "      <td>40.795376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-21</th>\n",
       "      <td>41.549999</td>\n",
       "      <td>42.039291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-22</th>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.303471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-23</th>\n",
       "      <td>41.279999</td>\n",
       "      <td>41.344379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>40.799999</td>\n",
       "      <td>41.406124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>40.820000</td>\n",
       "      <td>40.954197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Real  Predicted\n",
       "Date                            \n",
       "2017-09-12  40.573196  40.314247\n",
       "2017-09-13  40.540672  40.489613\n",
       "2017-09-14  40.719521  40.694805\n",
       "2017-09-15  40.768295  40.779522\n",
       "2017-09-18  40.922752  40.795376\n",
       "...               ...        ...\n",
       "2020-12-21  41.549999  42.039291\n",
       "2020-12-22  41.230000  41.303471\n",
       "2020-12-23  41.279999  41.344379\n",
       "2020-12-29  40.799999  41.406124\n",
       "2020-12-30  40.820000  40.954197\n",
       "\n",
       "[806 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Actual Vs. Predicted Prices'}, xlabel='Date'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stocks.plot(title=\"Actual Vs. Predicted Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.062136018246633715"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks[\"diff\"] = stocks[\"Real\"] - stocks[\"Predicted\"]\n",
    "stocks[\"diff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "file_path = Path(\"enb_model_1.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
